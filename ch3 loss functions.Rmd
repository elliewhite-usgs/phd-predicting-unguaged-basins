---
title: "lossfunctions"
author: "Ellie White"
date: "March 2, 2019"
output: html_document
---

Record of how a model will behave given different loss functions on hydrologic data. 

# Contents   
1.0 Data Gathering
2.0 Data Transformations
3.0 Functions
4.0 Modelling anf Resampling
5.0 GOF Post Processing
6.0 Plots
  6.1 Timeseries Visual Fit  
  6.2 GOF Comparisons
  6.3 Observed vs. Predicted
  6.4 Density Plots
  6.5 Map Plots
  6.6 Dotcharts
  6.7 Boxplots
  6.8 GIFs

# Libraries  
 
```{r, include=FALSE}
library(knitr)
library(formatR)
opts_chunk$set(
  fig.width  = 7.5,
  fig.height = 7.5,
  collapse   = TRUE,
  tidy       = FALSE
)
```

# Citations
```{r citations}
# cite R 
toBibtex(citation())

# cite R studio
RStudio.Version()

# cite packages
citethese <- c("lattice", "grid")
for(i in seq_along(citethese)){
  x <- citation(citethese[i])
  print(toBibtex(x))
}

remove(citethese)
sessionInfo()
```

# Conceptual Plots
```{r visuals}
# colourblind palettes
# ordered:     black      pink        orange     yellow     green       blue      darkorange  lightblue
cbpgrey <-  c("#999999", "#CC79A7",  "#E69F00", "#F0E442", "#009E73", "#0072B2", "#D55E00", "#56B4E9")
cbpblack <- c("#000000", "#CC79A7",  "#E69F00", "#F0E442", "#009E73", "#0072B2", "#D55E00", "#56B4E9")
```

```{r conceptual_plots}
l2 <- function(x){x^2}                                 # MSE
l1 <- function(x){abs(x)}                              # MAE
linex <- function(x,phi=1){exp(phi*x)-phi*x-1}         # LINEX
linex2 <- function(x,phi=-1){exp(phi*x)-phi*x-1}       # LINEX
wlse <- function(x, alpha=1.2){alpha*x^2}              # WLSE
wlse2 <- function(x, alpha=-2){alpha*x^2}              # WLSE
logcosh <- function(x){log(cosh(x))}                   # LOGCOSH

png('ch3 loss functions/outputdata/rplot31_lossfuncs1.png', width=3.25, height=2.85, units="in", pointsize=12, res=1200)
par(mar=c(3,3,1,1)+0.1, ps=8, cex = 1, mgp = c(2,1,0))
curve(l2, from=-3, to=3, xlab="Errors", ylab="Cost", col=cbpblack[2])
curve(l1, add=TRUE, lty=2, col=cbpblack[3])
curve(linex, add=TRUE, lty=3, col=cbpblack[4])
curve(linex2, add=TRUE, lty=4, col=cbpblack[5])
legend("top", horiz=FALSE, inset=c(0, 0.01), c("squared", "absolute", "linex, phi=1", "linex, phi=-1"), lty=c(1,2,3,4), col=cbpblack[2:6], bg="grey96", cex=0.8, box.lty=0)
dev.off()

png('ch3 loss functions/outputdata/rplot31_lossfuncs2.png', width=6.5, height=2, units="in", pointsize=12, res=1200)
par(mar=c(3,3,1,1)+0.1, ps=8, cex = 1, mgp = c(2,1,0), mfrow=c(1,4))
curve(l2, from=-3, to=3, xlab="Errors", ylab="Cost", col=cbpblack[8], main="squared")
curve(l1, from=-3, to=3, xlab="Errors", ylab="Cost",  col=cbpblack[8], main="absolute value")
curve(linex, from=-3, to=3, xlab="Errors", ylab="Cost",  col=cbpblack[8], main="linear-exponential, phi=1")
curve(linex2, from=-3, to=3, xlab="Errors", ylab="Cost", col=cbpblack[8], main="linear-exponential, phi=-1")
dev.off()

library("ggplot2")
aa <- data.frame(x=c(-2,2), category="L1 Norm")
bb <- data.frame(x=c(-2,2), category="L2 Norm")
cc <- data.frame(x=c(-2,2), category="LINEX phi=1")
dd <- data.frame(x=c(-2,2), category="LINEX phi=-1")
ee <- data.frame(x=c(-2,2), category="WLSE alpha=1.2")
ff <- data.frame(x=c(-2,2), category="Log-Cosh")

png('ch3 loss functions/outputdata/rplot31_lossfuncs3.png', width=6.5, height=4.5, units="in", pointsize=12, res=1200)
  ggplot(aa, aes(x)) + 
    stat_function(fun=l2) + 
    stat_function(data = bb, mapping = aes(x), fun = l1)+
    stat_function(data = ff, mapping = aes(x), fun = logcosh)+
    stat_function(data = cc, mapping = aes(x), fun = linex)+
    stat_function(data = dd, mapping = aes(x), fun = linex2)+
    stat_function(data = ee, mapping = aes(x), fun = wlse)+
    facet_wrap("category", scales = "free_x")+
    scale_colour_manual("loss functions", values=cbpblack[2:8])+
    theme_bw()
dev.off()
```

# Set Seed
```{r setseed}
set.seed(3232019)
```

# 1.0 Data Gathering
```{r data_gathering} 
df <- readRDS('inputdata/moddf.rds')

# remove DOMGEOLOGY cause it's causing problems
df <- df[ , !(colnames(df) %in% c("DOMGEOLOGY"))]

# order by baisn name
df <- df[order(df$CDEC_ID), ]
row.names(df) <- 1:nrow(df)

# get rid of negative flows
# 1st of all WHY THE FUCK ARE THERE NEGATIVE FLOWS IN THE DATA? inverstigate this later.
# 2nd make sure the dates that have negative flows in the original dataset is removed from the cumulative dataset too. Afterall, these cumulative values are calculated from the original dataset and negative flow don't make sense there, so their cumulative doesn't make sense in this dataset either. 
moddf <- df[df$FLOW>=0, ]

# check if all the negatives are gone from moddf and moddfc
tbd <- moddf[moddf$FLOW<0, "FLOW"]
tbd <- na.omit(tbd)
length(tbd) == 0

remove(tbd)
```

```{r data_gathering_extra}
# some helpful dataframes, may come in handy later for post processing
basins_points <- read.csv("inputdata/cdec_fnf_stations_data_minus_sfj_otr_bhn_ftm_sfr_sjm_klo.csv", stringsAsFactors = FALSE)
coordinates(basins_points) <- ~LONGITUDE+LATITUDE
proj4string(basins_points) <- CRS("+proj=longlat +datum=WGS84")

basins <- readRDS("inputdata/basins.rds")
cacounties <- readRDS("inputdata/counties.rds")

ta <- CRS("+proj=aea +lat_1=34 +lat_2=40.5 +lat_0=0 +lon_0=-120 +x_0=0 +y_0=-4000000 +datum=NAD83 +units=km +ellps=GRS80")
basins_points <- spTransform(basins_points, ta)
basins <- spTransform(basins, ta)
cacounties <- spTransform(cacounties, ta)
  
# wide format data
cdec_fnf_wide <- read.csv('inputdata/cdec_fnf_wide.csv')
cdec_fnf_wide$DATE <- as.Date(cdec_fnf_wide$DATE, format="%Y-%m-%d")
cdec_fnf_wide <- cdec_fnf_wide[order(cdec_fnf_wide$DATE),]

# The full records span 1900-01-01 to 1980-09-01, but most records start at 1982
cdec_fnf_wide <- cdec_fnf_wide[cdec_fnf_wide$DATE>="1982-01-01", ]
```

# 2.0 Data Tranformations
```{r data_transformation_lm} 
# split into two one original aggregate basins and one the incremental basins
df_lm_agg <- moddf[1:(which(moddf$CDEC_ID=="AMA_INC")[1]-1),]
df_lm_inc <- moddf[which(moddf$CDEC_ID=="AMA_INC")[1]:nrow(moddf),]

# get rid of na values 
df_lm_agg <- na.omit(df_lm_agg)
df_lm_inc <- na.omit(df_lm_inc)
```

# 3.0 Functions
```{r funcstoimport}
# library(hydroGOF) # this is giving wrong functions, do not load it in make sure the search path is clear
goffuncs <- list.files("libraries/HydroGOFm/R")
for(i in 1:length(goffuncs)){
  source(paste0("libraries/HydroGOFm/R/", goffuncs[i]))
}
remove(goffuncs)

search()
```

# 4.0 Modelling and Resampling
```{r lm_custom_losses}
# manual fitting of lm using optim
# first define the custom losses as functions to be passed to the optim function when fitting
# X is the matrix of predictors
# y is the vector of response variables 
# par is the number of parameters

min_ls <- function(X, y, par) { 
  m <- length(y)
  j <- sum((rowSums(X*par)- y)^2)/(2*m)
  return(j)
}

min_lad <- function(X, y, par) {
  m <- length(y)
  j <- sum(abs(rowSums(X*par)- y))/(2*m)
  return(j)
}

min_wls <- function(X, y, par, alphad=0.00001, betad=0.00005, alphaf=0.00005, betaf=0.00001) {
  if(betad<alphad | betaf>alphaf){
    print("Warning! The drought and flood weights specified are wrong. Make sure betad>alphad and betaf<alphaf!")
  }
  Xy <- cbind(X, y)
  
  Xyd <- Xy[Xy$FLOOD==0, ]
  Xd <- within(Xyd, rm(y))
  Xd <- within(Xd, rm(FLOOD))
  yd <- Xyd$y
  md <- length(yd)
  
  Xyf <- Xy[Xy$FLOOD==1, ]
  Xf <- within(Xyf, rm(y))
  Xf <- within(Xf, rm(FLOOD))
  yf <- Xyf$y
  mf <- length(yf)
  
  mincompd <- rowSums(Xd*par)-yd
  mincompd[mincompd > 0] <- 0
  maxcompd <- rowSums(Xd*par)-yd
  maxcompd[maxcompd < 0] <- 0
  
  mincompf <- rowSums(Xf*par)-yf
  mincompf[mincompf > 0] <- 0
  maxcompf <- rowSums(Xf*par)-yf
  maxcompf[maxcompf < 0] <- 0
  
  jd <- sum(alphad*mincompd^2 + betad*maxcompd^2)/(2*md) # drought weights
  jf <- sum(alphaf*mincompf^2 + betaf*maxcompf^2)/(2*mf) # flood weights
  j <- jd+jf
  return(j)
}

min_linex <- function(X, y, par, phif=0.0001, phid=-0.0001) {
  # phi is positive for floods, negative for droughts
  if(phif<=0 | phid>=0){
    print("Warning! The drought and flood weights specified are wrong. Make sure phif>0 and phid<0!")
  }
  Xy <- cbind(X, y)
  
  Xyd <- Xy[Xy$FLOOD==0, ]
  Xd <- within(Xyd, rm(y))
  Xd <- within(Xd, rm(FLOOD))
  yd <- Xyd$y
  md <- length(yd)
  
  Xyf <- Xy[Xy$FLOOD==1, ]
  Xf <- within(Xyf, rm(y))
  Xf <- within(Xf, rm(FLOOD))
  yf <- Xyf$y
  mf <- length(yf)
  
  jd <- sum(exp(phid*(rowSums(Xd*par)-yd))-phid*(rowSums(Xd*par)-yd)-1)/(2*md) # drought weights
  jf <- sum(exp(phif*(rowSums(Xf*par)-yf))-phif*(rowSums(Xf*par)-yf)-1)/(2*mf) # flood weights
  
  # exp(phid*(rowSums(Xd*optimmodel[[1]]$par)-yd))- phid*(rowSums(Xd*optimmodel[[1]]$par)-yd) -1
  
  #df[!is.infinite(rowSums(df)),]
  #sum(exp(phid*(Xd*optimmodel[[1]]$par-yd))-phid*(Xd*optimmodel[[1]]$par-yd)-1)/(2*md)
  
  j <- jd+jf
  return(j)
}
```

```{r lmrmod}
# use row numbers as nforstitch, no need for a new column in results
lmloss <- function(data, losstype){
  optimmodel <- results <- modgof <- list()
  
  for (k in 1:(length(unique(data$CDEC_ID)))){
    h <- unique(data$CDEC_ID)[k]
    testset <- data[data$CDEC_ID==h,]
    trainset <- data[data$CDEC_ID!=h,]
    
    # for symmetric losses use the following
    x <- trainset[,c(15,18:(ncol(trainset)-1))] # predictors only 
    x_centered <- scale(x, scale=FALSE) # centered for tls model
    y <- trainset$FLOW # response only
    m <- length(y) # number of observations
    X <- cbind(rep(1, m), x) # adding a column of 1s as intercept to the design matrix x
    theta <- rep(1,26) # beta parameter starting points
    
    # for asymmetric losses use these instead. y, m and theta do not change, add a flood/drought classifier
    floodlvl_mean <- aggregate(PPT~CDEC_ID, data=trainset, FUN=mean)
    floodlvl_median <- aggregate(PPT~CDEC_ID, data=trainset, FUN=median)
    colnames(floodlvl_mean)[2] <- "FLVL_MEAN"
    colnames(floodlvl_median)[2] <- "FLVL_MEDIAN"
    trainset2 <- merge(trainset, floodlvl_mean, by="CDEC_ID")
    trainset2$FLOOD <- ifelse(trainset2$PPT>trainset2$FLVL_MEAN, 1, 0) # designate each observation as a flood:1 or a drought:0
    x2 <- trainset2[,c(15,18:41,44)] # predictors only, now including a flood designation column
    X2 <- cbind(rep(1, m), x2) # adding a column of 1s as intercept to the design matrix x
    
    if(losstype=="ls"){
      optimmodel[[k]] <- optim(par=theta, fn=min_ls, X=X, y=y, method="BFGS")
      forpredicting <- cbind(1, testset[,c(15,18:(ncol(testset)-1))])
      predictions <- rowSums(t(t(forpredicting)*optimmodel[[k]]$par))
      results[[k]] <- cbind(obs=testset$FLOW, pred=predictions)
      modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs)  
    }
    
    if(losstype=="lad"){
      optimmodel[[k]] <- optim(par=theta, fn=min_lad, X=X, y=y, method="BFGS")
      forpredicting <- cbind(1, testset[,c(15,18:(ncol(testset)-1))])
      predictions <- rowSums(t(t(forpredicting)*optimmodel[[k]]$par))
      results[[k]] <- cbind(obs=testset$FLOW, pred=predictions)
      modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs)    
    }
    
    if(losstype=="tls"){
      optimmodel[[k]] <- prcomp(cbind(x_centered,y))$rotation
      beta <- -optimmodel[[k]][-ncol(optimmodel[[k]]),ncol(optimmodel[[k]])] / optimmodel[[k]][ncol(optimmodel[[k]]),ncol(optimmodel[[k]])]
      forpredicting <- testset[,c(15,18:(ncol(testset)-1))] # notice we no longer have an interecpt so no need to cbind a column of 1s!
      predictions <- rowSums(t(t(forpredicting)*beta))
      results[[k]] <- cbind(obs=testset$FLOW, pred=predictions)
      modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs) 
    }
    
    if(losstype=="wls"){
      optimmodel[[k]] <- optim(par=theta, fn=min_wls, X=X2, y=y, method="BFGS")
      forpredicting <- cbind(1, testset[,c(15,18:(ncol(testset)-1))])
      predictions <- rowSums(t(t(forpredicting)*optimmodel[[k]]$par))
      results[[k]] <- cbind(obs=testset$FLOW, pred=predictions)
      modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs) 
    }
    
    if(losstype=="linex"){
      optimmodel[[k]] <- optim(par=theta, fn=min_linex, X=X2, y=y, method="BFGS")
      forpredicting <- cbind(1, testset[,c(15,18:(ncol(testset)-1))])
      predictions <- rowSums(t(t(forpredicting)*optimmodel[[k]]$par))
      results[[k]] <- cbind(obs=testset$FLOW, pred=predictions)
      modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs)
    }
  }
  
  names_tbd <- rownames(modgof[[1]])
  modgof <- data.frame(matrix(unlist(modgof), nrow=length(modgof[[1]]), byrow=FALSE))
  rownames(modgof) <- names_tbd
  colnames(modgof) <- unique(data$CDEC_ID)
  list(mod=optimmodel, results=results, gof=modgof)
}

# lm_agg_logo_ls_results <- lmloss(df_lm_agg, "ls")
# lm_agg_logo_lad_results <- lmloss(df_lm_agg, "lad")
# lm_agg_logo_tls_results <- lmloss(df_lm_agg, "tls")
# lm_agg_logo_wls_results <- lmloss(df_lm_agg, "wls")
# lm_agg_logo_linex_results <- lmloss(df_lm_agg, "linex")

# saveRDS(lm_agg_logo_ls_results, file="ch3 loss functions/outputdata/rds/lm_agg_logo_ls_results.RDS")
# saveRDS(lm_agg_logo_lad_results, file="ch3 loss functions/outputdata/rds/lm_agg_logo_lad_results.RDS")
# saveRDS(lm_agg_logo_tls_results, file="ch3 loss functions/outputdata/rds/lm_agg_logo_tls_results.RDS")
# saveRDS(lm_agg_logo_wls_results, file="ch3 loss functions/outputdata/rds/lm_agg_logo_wls_results.RDS")
# saveRDS(lm_agg_logo_linex_results, file="ch3 loss functions/outputdata/rds/lm_agg_logo_linex_results.RDS")

# the inc ones are saved in the rds folder but we are not loading them in
lm_agg_logo_ls_results <- readRDS("ch3 loss functions/outputdata/rds/lm_agg_logo_ls_results.RDS")
lm_agg_logo_lad_results <- readRDS("ch3 loss functions/outputdata/rds/lm_agg_logo_lad_results.RDS")
lm_agg_logo_tls_results <- readRDS("ch3 loss functions/outputdata/rds/lm_agg_logo_tls_results.RDS")
lm_agg_logo_wls_results <- readRDS("ch3 loss functions/outputdata/rds/lm_agg_logo_wls_results.RDS")
lm_agg_logo_linex_results <- readRDS("ch3 loss functions/outputdata/rds/lm_agg_logo_linex_results.RDS") 
```

Since none of those models are handling the 0s well, let's consider a Tobit and two-part model.
```{r tobitmod}
# these libraries use a maximum likelihood method of fitting the coefficents. So let's write our own
# library(censReg)
# library(AER)

tbmloss <- function(data, losstype){
  optimmodel <- results <- modgof <- list()
  
  for (k in 1:(length(unique(data$CDEC_ID)))){
    h <- unique(data$CDEC_ID)[k]
    testset <- data[data$CDEC_ID==h,]
    trainset <- data[data$CDEC_ID!=h,]
    
    # for symmetric losses use the following
    x <- trainset[,c(15,18:(ncol(trainset)-1))] # predictors only 
    x_centered <- scale(x, scale=FALSE) # centered for tls model
    y <- trainset$FLOW # response only
    m <- length(y) # number of observations
    X <- cbind(rep(1, m), x) # adding a column of 1s as intercept to the design matrix x
    theta <- rep(1,26) # beta parameter starting points
    
    # for asymmetric losses use these instead. y, m and theta do not change, add a flood/drought classifier
    floodlvl_mean <- aggregate(PPT~CDEC_ID, data=trainset, FUN=mean)
    floodlvl_median <- aggregate(PPT~CDEC_ID, data=trainset, FUN=median)
    colnames(floodlvl_mean)[2] <- "FLVL_MEAN"
    colnames(floodlvl_median)[2] <- "FLVL_MEDIAN"
    trainset2 <- merge(trainset, floodlvl_mean, by="CDEC_ID")
    trainset2$FLOOD <- ifelse(trainset2$PPT>trainset2$FLVL_MEAN, 1, 0) # designate each observation as a flood:1 or a drought:0
    x2 <- trainset2[,c(15,18:41,44)] # predictors only, now including a flood designation column
    X2 <- cbind(rep(1, m), x2) # adding a column of 1s as intercept to the design matrix x
    
    if(losstype=="ls"){
      optimmodel[[k]] <- optim(par=theta, fn=min_ls, X=X, y=y, method="BFGS")
      forpredicting <- cbind(1, testset[,c(15,18:(ncol(testset)-1))])
      predictions <- rowSums(t(t(forpredicting)*optimmodel[[k]]$par))
      tbpredictions <- ifelse(predictions<0, 0, predictions)
      results[[k]] <- cbind(obs=testset$FLOW, pred=tbpredictions)
      modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs)  
    }
    
    if(losstype=="lad"){
      optimmodel[[k]] <- optim(par=theta, fn=min_lad, X=X, y=y, method="BFGS")
      forpredicting <- cbind(1, testset[,c(15,18:(ncol(testset)-1))])
      predictions <- rowSums(t(t(forpredicting)*optimmodel[[k]]$par))
      tbpredictions <- ifelse(predictions<0, 0, predictions)
      results[[k]] <- cbind(obs=testset$FLOW, pred=tbpredictions)
      modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs)    
    }
    
    if(losstype=="tls"){
      optimmodel[[k]] <- prcomp(cbind(x_centered,y))$rotation
      beta <- -optimmodel[[k]][-ncol(optimmodel[[k]]),ncol(optimmodel[[k]])] / optimmodel[[k]][ncol(optimmodel[[k]]),ncol(optimmodel[[k]])]
      forpredicting <- testset[,c(15,18:(ncol(testset)-1))] # notice we no longer have an interecpt so no need to cbind a column of 1s!
      predictions <- rowSums(t(t(forpredicting)*beta))
      tbpredictions <- ifelse(predictions<0, 0, predictions)
      results[[k]] <- cbind(obs=testset$FLOW, pred=tbpredictions)
      modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs) 
    }
    
    if(losstype=="wls"){
      optimmodel[[k]] <- optim(par=theta, fn=min_wls, X=X2, y=y, method="BFGS")
      forpredicting <- cbind(1, testset[,c(15,18:(ncol(testset)-1))])
      predictions <- rowSums(t(t(forpredicting)*optimmodel[[k]]$par))
      tbpredictions <- ifelse(predictions<0, 0, predictions)
      results[[k]] <- cbind(obs=testset$FLOW, pred=tbpredictions)
      modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs) 
    }
    
    if(losstype=="linex"){
      optimmodel[[k]] <- optim(par=theta, fn=min_linex, X=X2, y=y, method="BFGS")
      forpredicting <- cbind(1, testset[,c(15,18:(ncol(testset)-1))])
      predictions <- rowSums(t(t(forpredicting)*optimmodel[[k]]$par))
      tbpredictions <- ifelse(predictions<0, 0, predictions)
      results[[k]] <- cbind(obs=testset$FLOW, pred=tbpredictions)
      modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs)
    }
  }
  
  names_tbd <- rownames(modgof[[1]])
  modgof <- data.frame(matrix(unlist(modgof), nrow=length(modgof[[1]]), byrow=FALSE))
  rownames(modgof) <- names_tbd
  colnames(modgof) <- unique(data$CDEC_ID)
  list(mod=optimmodel, results=results, gof=modgof)
}

# tbm_agg_logo_ls_results <- tbmloss(df_lm_agg, "ls")
# tbm_agg_logo_lad_results <- tbmloss(df_lm_agg, "lad")
# tbm_agg_logo_tls_results <- tbmloss(df_lm_agg, "tls")
# tbm_agg_logo_wls_results <- tbmloss(df_lm_agg, "wls")
# tbm_agg_logo_linex_results <- tbmloss(df_lm_agg, "linex")
# 
# saveRDS(tbm_agg_logo_ls_results, file="ch3 loss functions/outputdata/rds/tbm_agg_logo_ls_results.RDS")
# saveRDS(tbm_agg_logo_lad_results, file="ch3 loss functions/outputdata/rds/tbm_agg_logo_lad_results.RDS")
# saveRDS(tbm_agg_logo_tls_results, file="ch3 loss functions/outputdata/rds/tbm_agg_logo_tls_results.RDS")
# saveRDS(tbm_agg_logo_wls_results, file="ch3 loss functions/outputdata/rds/tbm_agg_logo_wls_results.RDS")
# saveRDS(tbm_agg_logo_linex_results, file="ch3 loss functions/outputdata/rds/tbm_agg_logo_linex_results.RDS")
# 
# tbm_agg_logo_ls_results <- readRDS("ch3 loss functions/outputdata/rds/tbm_agg_logo_ls_results.RDS")
# tbm_agg_logo_lad_results <- readRDS("ch3 loss functions/outputdata/rds/tbm_agg_logo_lad_results.RDS")
# tbm_agg_logo_tls_results <- readRDS("ch3 loss functions/outputdata/rds/tbm_agg_logo_tls_results.RDS")
# tbm_agg_logo_wls_results <- readRDS("ch3 loss functions/outputdata/rds/tbm_agg_logo_wls_results.RDS")
# tbm_agg_logo_linex_results <- readRDS("ch3 loss functions/outputdata/rds/tbm_agg_logo_linex_results.RDS")
# 
# mean(unlist(tbm_agg_logo_ls_results[["gof"]]["bR2", ]))
# mean(unlist(lm_agg_logo_ls_results[["gof"]]["bR2", ]))

# why are the lm and tbm producing the exact same results?
```

```{r twopartmod}
# not done yet
# can two-part models be fit with a loss function? or are they always fit with a max likelihood?
# 1st stage: binomial model to predict whether the values are 0 or >0
# binommodel
  
  
# 2nd stage: use linear model to model the observed non-zero vlaues
    
    
tpmcvloss <- function(data, losstype){
  
  binommodel <- optimmodel <- results <- modgof <- list()
  for (k in 1:(length(unique(data$CDEC_ID)))){
    h <- unique(data$CDEC_ID)[k]
    testset <- data[data$CDEC_ID==h,]
    trainset <- data[data$CDEC_ID!=h,]
    
    # seperate the data in zeros and positives 
    
    # for symmetric losses use the following
    x <- trainset[,c(15,18:(ncol(trainset)-1))] # predictors only 
    x_centered <- scale(x, scale=FALSE) # centered for tls model
    y <- trainset$FLOW # response only
    m <- length(y) # number of observations
    X <- cbind(rep(1, m), x) # adding a column of 1s as intercept to the design matrix x
    theta <- rep(1,26) # beta parameter starting points
    
    # for asymmetric losses use these instead. y, m and theta do not change, add a flood/drought classifier
    floodlvl_mean <- aggregate(PPT~CDEC_ID, data=trainset, FUN=mean)
    floodlvl_median <- aggregate(PPT~CDEC_ID, data=trainset, FUN=median)
    colnames(floodlvl_mean)[2] <- "FLVL_MEAN"
    colnames(floodlvl_median)[2] <- "FLVL_MEDIAN"
    trainset2 <- merge(trainset, floodlvl_mean, by="CDEC_ID")
    trainset2$FLOOD <- ifelse(trainset2$PPT>trainset2$FLVL_MEAN, 1, 0) # designate each observation as a flood:1 or a drought:0
    x2 <- trainset2[,c(15,18:41,44)] # predictors only, now including a flood designation column
    X2 <- cbind(rep(1, m), x2) # adding a column of 1s as intercept to the design matrix x
    
    if(losstype=="ls"){
      binommodel[[k]] <- 
      optimmodel[[k]] <- optim(par=theta, fn=min_ls, X=X, y=y, method="BFGS")
      forpredicting <- cbind(1, testset[,c(15,18:(ncol(testset)-1))])
      predictions <- rowSums(t(t(forpredicting)*optimmodel[[k]]$par))
      results[[k]] <- cbind(obs=testset$FLOW, pred=predictions)
      modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs)  
    }
    
    if(losstype=="lad"){
      optimmodel[[k]] <- optim(par=theta, fn=min_lad, X=X, y=y, method="BFGS")
      forpredicting <- cbind(1, testset[,c(15,18:(ncol(testset)-1))])
      predictions <- rowSums(t(t(forpredicting)*optimmodel[[k]]$par))
      results[[k]] <- cbind(obs=testset$FLOW, pred=predictions)
      modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs)    
    }
    
    if(losstype=="tls"){
      optimmodel[[k]] <- prcomp(cbind(x_centered,y))$rotation
      beta <- -optimmodel[[k]][-ncol(optimmodel[[k]]),ncol(optimmodel[[k]])] / optimmodel[[k]][ncol(optimmodel[[k]]),ncol(optimmodel[[k]])]
      forpredicting <- testset[,c(15,18:(ncol(testset)-1))] # notice we no longer have an interecpt so no need to cbind a column of 1s!
      predictions <- rowSums(t(t(forpredicting)*beta))
      results[[k]] <- cbind(obs=testset$FLOW, pred=predictions)
      modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs) 
    }
    
    if(losstype=="wls"){
      optimmodel[[k]] <- optim(par=theta, fn=min_wls, X=X2, y=y, method="BFGS")
      forpredicting <- cbind(1, testset[,c(15,18:(ncol(testset)-1))])
      predictions <- rowSums(t(t(forpredicting)*optimmodel[[k]]$par))
      results[[k]] <- cbind(obs=testset$FLOW, pred=predictions)
      modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs) 
    }
    
    if(losstype=="linex"){
      optimmodel[[k]] <- optim(par=theta, fn=min_linex, X=X2, y=y, method="BFGS")
      forpredicting <- cbind(1, testset[,c(15,18:(ncol(testset)-1))])
      predictions <- rowSums(t(t(forpredicting)*optimmodel[[k]]$par))
      results[[k]] <- cbind(obs=testset$FLOW, pred=predictions)
      modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs)
    }
  }
  
  names_tbd <- rownames(modgof[[1]])
  modgof <- data.frame(matrix(unlist(modgof), nrow=length(modgof[[1]]), byrow=FALSE))
  rownames(modgof) <- names_tbd
  colnames(modgof) <- unique(data$CDEC_ID)
  list(mod=optimmodel, results=results, gof=modgof)
}

# lm_inc_logo_ls_results <- tpmcvloss(df_lm_inc, "ls")
# lm_inc_logo_lad_results <- tpmcvloss(df_lm_inc, "lad")
# lm_inc_logo_tls_results <- tpmcvloss(df_lm_inc, "tls")
# lm_inc_logo_wls_results <- tpmcvloss(df_lm_inc, "wls")
# lm_inc_logo_linex_results <- tpmcvloss(df_lm_inc, "linex")
```

here are some of the loss functions provided by the R interface to Keras:
keras::loss_mean_absolute_error()
keras::loss_mean_absolute_percentage_error()
keras::loss_mean_squared_error()
keras::loss_mean_squared_logarithmic_error()

example built in loss functions in python
def mean_squared_error(y_true, y_pred):
    return K.mean(K.square(y_pred - y_true), axis=-1)

def mean_squared_logarithmic_error(y_true, y_pred):
    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)
    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)
    return K.mean(K.square(first_log - second_log), axis=-1)

The original keras function uses the clip operation to make sure that negative values are not passed to the log function, and adding 1 to the clip result makes sure that all log transformed inputs will have non-negative results. We will do something similar here. However, we will use the relu operation rather than the clip operation.

For Asymmetric Functions
A loss function in keras must accept only 2 arguments: y_true and y_pred, which are the target tensor and model output tensor, correspondingly. But what if we want our loss/metric to depend on other tensors other than these two? To accomplish this, we will need to use "function closure." We will create a loss function (with whichever arguments we like) which returns a function of y_true and y_pred.

I would like to pass a vector that is outside of the training data, but the same length as the training data, to a custom loss function. The vector represents a post-prediction funnel (weights) that an observation has to pass through before they can yield (one or zero). Obviously, I can't use this funnel as a feature, but I would like to use it in a loss function. This funnel designates each observation and prediction pair as a flood or a drought and assigns different pairs of weights to them.

CANNOT have other parameters that y_true, y_pred in the loss function! So, the purpose of the wrapper function is to calculate auxiliary values for the complete loss function. It returns a *function* which calculates the complete loss given only the input and target output!
```{r nnmod}
# clean install of reticulate seems to resolve name errors
# devtools::install_github("rstudio/reticulate", force=T)
# seems like this resolved errors including error 2 in installing a keras environment on the watershed computer
library(reticulate)

# install and set up our environment for deep learning
library(tensorflow)
# install_tensorflow()
# devtools::install_github("rstudio/keras", force=T)
library(keras)
# keras::install_keras(method = "conda") # or use this: install_keras(method = "conda")

# for normalizing data
library (caret)

# custom losses
# the custom loss functions for R need to operate on tensor objects rather than R primitives. In order to perform these operations, you need to get a reference to the backend using backend(). In my system configuration, this returns a reference to tensorflow.

# mean absolute log error
male <- function(y_true, y_pred){
  K <- backend()
  K$mean(K$abs(K$log(K$relu(y_true) + 1) - K$log(K$relu(y_pred) + 1)))
}

# mean squared absolute log error
msale <- function(y_true, y_pred){
  K <- backend()
  K$mean(K$pow(K$abs(K$log(K$relu(y_true) + 1) - K$log(K$relu(y_pred) + 1)), 2))
}

mspe <- function(y_true, y_pred){
  K <- backend()
  # added a 1 to y_true, because dividing by 0 is a problem. In the cases where y_true=0, the mspe function turns into a simple mse.
  mod_loss <- K$mean(K$pow((K$flatten(y_pred)-K$flatten(y_true))/K$flatten(y_true+1), 2))
  return(mod_loss)
}

# When you write your custom design loss function, please keep in mind that it won’t handle batch training unless you specifically tell it how to. Basically, you have to take the average loss over each example in the batch!!!
wlse <- function(y_true, y_pred, flood_vect, alphad, betad, alphaf, betaf){
  alpha_vect <- ifelse(flood_vect==0, alphad, alphaf)
  beta_vect <- ifelse(flood_vect==0, betad, betaf)
  K <- backend()
  alpha_vect_cte <- K$constant(alpha_vect, dtype='float32')
  beta_vect_cte <- K$constant(beta_vect, dtype='float32')
  alpha_loss <- K$transpose(alpha_vect_cte)*K$cast(K$pow(K$minimum(0, K$flatten(y_pred)-K$flatten(y_true)), 2), dtype='float32')
  beta_loss <- K$transpose(beta_vect_cte)*K$cast(K$pow(K$maximum(0, K$flatten(y_pred)-K$flatten(y_true)), 2), dtype='float32')
  mod_loss <- K$sum(alpha_loss + beta_loss)*10^-6
  return(mod_loss)
}

wlse_wrapper_stochastic <- custom_metric("wlse", function(y_true, y_pred){
  wlse(y_true, y_pred, flood_vect=trainsetpvs2[, "FLOOD"], alphad=0.00001, betad=0.00005, alphaf=0.00005, betaf=0.00001)
})

linexe <- function(y_true, y_pred, flood_vect, phid, phif){
  phi_vect <- ifelse(flood_vect==0, phid, phif)
  K <- backend()
  phi_vect_cte <- K$constant(phi_vect, dtype='float32')
  exp_loss <- K$exp(K$transpose(phi_vect_cte)*K$cast(K$flatten(10^-6*(y_true-y_pred)), dtype='float32'))
  lin_loss <- K$transpose(phi_vect_cte)*K$cast(K$flatten(10^-6*(y_true-y_pred)), dtype='float32') + 1
  # unlike minibatch K$mean works, because we know batch_size=nrow(trainsetpvs)
  mod_loss <- 10^6*(K$mean(exp_loss-lin_loss)) # added a beta in the beginning
  # K$get_value(mod_loss)
  return(mod_loss) 
}

linexe_wrapper_stochastic <- custom_metric("linexe", function(y_true, y_pred){
  # make sure phid is positive, and phif is negative
  linexe(y_true, y_pred, flood_vect=trainsetpvs2[, "FLOOD"], phid=1.0, phif=-1.5)
})

# need to write a wlse_wrapper_minibatch function if you want to speed up training. For now just use long epochs. 

# example y_true and y_pred to play with
#y_true=trainsetrv
#y_pred=trainsetrv*1.1+10000
#y_pred=y_true*2-rnorm(nrow(trainsetpvs2), 0, 0.01)*20000

nnloss <- function(data, losstype){
  optimmodel <- results <- modgof <- list()
  
  for (k in 1:(length(unique(data$CDEC_ID)))){
    h <- unique(data$CDEC_ID)[k]
    testset <- data[data$CDEC_ID==h,]
    trainset <- data[data$CDEC_ID!=h,]
    
    # for symmetric losses: seperate into predictor variables and response variable
    testsetpvs <- as.matrix(testset[,c(15,18:(ncol(testset)-1))])
    trainsetpvs <- as.matrix(trainset[,c(15,18:(ncol(trainset)-1))])
    testsetrv <- as.matrix(testset$FLOW)
    trainsetrv <- as.matrix(trainset$FLOW)
    
    # for asymmetric losses: designate each observation as a flood:1 or a drought:0 for asymmetric losses
    floodlvl_mean <- aggregate(PPT~CDEC_ID, data=trainset, FUN=mean)
    colnames(floodlvl_mean)[2] <- "FLVL_MEAN"
    trainset <- merge(trainset, floodlvl_mean, by="CDEC_ID")
    trainset$FLOOD <- ifelse(trainset$PPT>trainset$FLVL_MEAN, 1, 0) 
    trainsetpvs2 <- as.matrix(trainset[,c(15, 18:41, 44)]) 
    trainsetrv2 <- as.matrix(trainset$FLOW)
    
    # normalize the training set on standard deviation, then normalize testset by using mean and SD of training set so no leaks happen
    scale_par <- preProcess(trainsetpvs, method=c("scale"))
    trainsetpvs_scaled <- data.frame(predict(scale_par, trainsetpvs))
    testsetpvs_scaled <- predict(scale_par, testsetpvs) # this should remain a matrix
    # add in the flood column, since the data wasn't shuffled just columnbind
    trainsetpvs_scaled2 <- trainsetpvs_scaled
    trainsetpvs_scaled2$FLOOD <- trainset$FLOOD
    trainsetpvs_scaled2 <- as.matrix(trainsetpvs_scaled2) # back to matrix form 
    trainsetpvs_scaled <- as.matrix(trainsetpvs_scaled)
    
    # the model network includes two layers of fully-connected relu activated neurons, and an output layer with no transformation. units are the number of hidden nodes
    nnmodel <- keras_model_sequential() %>% # use: "relu", "sigmoid", "softmax"
      layer_dense(units=64, activation="relu", input_shape=dim(trainsetpvs)[[2]]) %>%
      layer_dense(units=64, activation="relu") %>%
      layer_dense(units=1) # number of outputs, here we just want one prediction
    
    # first, losses provided by keras
    if(losstype=="mse"){
      nnmodel %>% # to compile the model, loss functions are defined here
        compile(optimizer="rmsprop", loss=keras::loss_mean_squared_error, metrics=c("mae"))
      nnmodel %>%  # this is to fit the model coefficients
        fit(trainsetpvs, trainsetrv, epochs=100, batch_size=25, verbose=1, validation_split=0.2)
      predictions <- nnmodel %>% predict(testsetpvs)
      predictions <- predictions[ , 1] # because output layer was specified to be of unit=1
      results[[k]] <- cbind(obs=testsetrv[ , 1], pred=predictions, nforstitch=as.numeric(rownames(testset)))
      modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs)
    }
    
    if(losstype=="mae"){
      nnmodel %>% 
        compile(optimizer="rmsprop", loss=keras::loss_mean_absolute_error, metrics=c("mae"))
      nnmodel %>% 
        fit(trainsetpvs, trainsetrv, epochs=100, batch_size=25, verbose=1, validation_split=0.2)
      predictions <- nnmodel %>% predict(testsetpvs)
      predictions <- predictions[ , 1] 
      results[[k]] <- cbind(obs=testsetrv[ , 1], pred=predictions, nforstitch=as.numeric(rownames(testset)))
      modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs)
    }
    
    if(losstype=="msle"){ 
      nnmodel %>% 
        compile(optimizer="rmsprop", loss=keras::loss_mean_squared_logarithmic_error, metrics=c("mae"))
      nnmodel %>% 
        fit(trainsetpvs, trainsetrv, epochs=100, batch_size=25, verbose=1, validation_split=0.2)
      predictions <- nnmodel %>% predict(testsetpvs)
      predictions <- predictions[ , 1] 
      results[[k]] <- cbind(obs=testsetrv[ , 1], pred=predictions, nforstitch=as.numeric(rownames(testset)))
      modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs)
    }
    
    if(losstype=="mape"){ 
      nnmodel %>% 
        compile(optimizer="rmsprop", loss=keras::loss_mean_absolute_percentage_error, metrics=c("mae"))
      nnmodel %>% 
        fit(trainsetpvs, trainsetrv, epochs=100, batch_size=25, verbose=1, validation_split=0.2)
      predictions <- nnmodel %>% predict(testsetpvs)
      predictions <- predictions[ , 1] 
      results[[k]] <- cbind(obs=testsetrv[ , 1], pred=predictions, nforstitch=as.numeric(rownames(testset)))
      modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs)
    }
    
    if(losstype=="logcosh"){
      nnmodel %>% 
        compile(optimizer="rmsprop", loss=keras::loss_logcosh, metrics=c("mae"))
      nnmodel %>% 
        fit(trainsetpvs, trainsetrv, epochs=100, batch_size=25, verbose=1, validation_split=0.2)
      predictions <- nnmodel %>% predict(testsetpvs)
      predictions <- predictions[ , 1] 
      results[[k]] <- cbind(obs=testsetrv[ , 1], pred=predictions, nforstitch=as.numeric(rownames(testset)))
      modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs)
    }
    
    # second, custom symmetric losses
    if(losstype=="mspe"){ 
      nnmodel %>% 
        compile(optimizer="rmsprop", loss=mspe, metrics=c("mae"))
      nnmodel %>% 
        fit(trainsetpvs, trainsetrv, epochs=100, batch_size=25, verbose=1, validation_split=0.2)
      predictions <- nnmodel %>% predict(testsetpvs)
      predictions <- predictions[ , 1] 
      results[[k]] <- cbind(obs=testsetrv[ , 1], pred=predictions, nforstitch=as.numeric(rownames(testset)))
      modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs)
    }
    
    if(losstype=="male"){ # custom mean log absolute error
      nnmodel %>% 
        compile(optimizer="rmsprop", loss=male, metrics=c("mae"))
      nnmodel %>% 
        fit(trainsetpvs, trainsetrv, epochs=100, batch_size=25, verbose=1, validation_split=0.2)
      predictions <- nnmodel %>% predict(testsetpvs)
      predictions <- predictions[ , 1] 
      results[[k]] <- cbind(obs=testsetrv[ , 1], pred=predictions, nforstitch=as.numeric(rownames(testset)))
      modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs)
    }
    
    if(losstype=="msale"){ # custom mean squared log absolute error
      nnmodel %>% 
        compile(optimizer="rmsprop", loss=msale, metrics=c("mae"))
      nnmodel %>% 
        fit(trainsetpvs, trainsetrv, epochs=100, batch_size=25, verbose=1, validation_split=0.2)
      predictions <- nnmodel %>% predict(testsetpvs)
      predictions <- predictions[ , 1] 
      results[[k]] <- cbind(obs=testsetrv[ , 1], pred=predictions, nforstitch=as.numeric(rownames(testset)))
      modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs)
    }
    
    # third, custom asymmetric losses
    # in fitting, make sure batch_size = nrow(train_x), shuffle = FALSE so that (y_true,y_pred) actually line up to the same observations. We need this beause we have flood/drought designations. Also, we cannot have a validation split if the batch_size is now the whole training set.
    # for some reason it's not working inside the function environment, so take it out and run the code chunck below instead.
    if(losstype=="wlse"){
      nnmodel %>% 
        compile(optimizer="rmsprop", loss=wlse_wrapper_stochastic, metrics=c("mae"))
      nnmodel %>% 
        fit(trainsetpvs, trainsetrv, epochs=1000, batch_size=nrow(trainsetpvs), shuffle=FALSE, verbose=1)
        predictions <- nnmodel %>% predict(testsetpvs)
        predictions <- predictions[ , 1] 
        results[[k]] <- cbind(obs=testsetrv[ , 1], pred=predictions, nforstitch=as.numeric(rownames(testset)))
        modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs)
    }

    if(losstype=="linexe"){
      nnmodel %>% 
        compile(optimizer="rmsprop", loss=linexe_wrapper_stochastic, metrics=c("mae"))
      nnmodel %>% 
        fit(trainsetpvs, trainsetrv, epochs=1000, verbose=1, batch_size=nrow(trainsetpvs), shuffle=FALSE)
      predictions <- nnmodel %>% predict(testsetpvs)
      predictions <- predictions[ , 1] 
      results[[k]] <- cbind(obs=testsetrv[ , 1], pred=predictions, nforstitch=as.numeric(rownames(testset)))
      modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs)
    }
    
    # check progress of the loop
    print(paste0("k=", k, ", Basin=", h))
  }
  
  names_tbd <- rownames(modgof[[1]])
  modgof <- data.frame(matrix(unlist(modgof), nrow=length(modgof[[1]]), byrow=FALSE))
  rownames(modgof) <- names_tbd
  colnames(modgof) <- unique(data$CDEC_ID)
  list(results=results, gof=modgof)
}

# nn_agg_logo_mse_results <- nnloss(df_lm_agg, "mse")
# saveRDS(nn_agg_logo_mse_results, file="ch3 loss functions/outputdata/rds/nn_agg_logo_mse_results.RDS")
# nn_agg_logo_mae_results <- nnloss(df_lm_agg, "mae")
# saveRDS(nn_agg_logo_mae_results, file="ch3 loss functions/outputdata/rds/nn_agg_logo_mae_results.RDS")
# nn_agg_logo_msle_results <- nnloss(df_lm_agg, "msle")
# saveRDS(nn_agg_logo_msle_results, file="ch3 loss functions/outputdata/rds/nn_agg_logo_msle_results.RDS")
# nn_agg_logo_mape_results <- nnloss(df_lm_agg, "mape")
# saveRDS(nn_agg_logo_mape_results, file="ch3 loss functions/outputdata/rds/nn_agg_logo_mape_results.RDS")
# nn_agg_logo_logcosh_results <- nnloss(df_lm_agg, "logcosh")
# saveRDS(nn_agg_logo_logcosh_results, file="ch3 loss functions/outputdata/rds/nn_agg_logo_logcosh_results.RDS")
# nn_agg_logo_mspe_results <- nnloss(df_lm_agg, "mspe")
# saveRDS(nn_agg_logo_mspe_results, file="ch3 loss functions/outputdata/rds/nn_agg_logo_mspe_results.RDS")
# nn_agg_logo_male_results <- nnloss(df_lm_agg, "male")
# saveRDS(nn_agg_logo_male_results, file="ch3 loss functions/outputdata/rds/nn_agg_logo_male_results.RDS")
# nn_agg_logo_msale_results <- nnloss(df_lm_agg, "msale")
# saveRDS(nn_agg_logo_msale_results, file="ch3 loss functions/outputdata/rds/nn_agg_logo_msale_results.RDS")

# not working, run code chunk below instead
# nn_agg_logo_wlse_results <- nnloss(df_lm_agg, "wlse")
# saveRDS(nn_agg_logo_wlse_results, file="ch3 loss functions/outputdata/rds/nn_agg_logo_wlse_results.RDS")
# nn_agg_logo_linexe_results <- nnloss(df_lm_agg, "linexe")
# saveRDS(nn_agg_logo_linexe_results, file="ch3 loss functions/outputdata/rds/nn_agg_logo_linexe_results.RDS")
```

```{r nn_wlse}
# # function environments not savind trainsetpvs2 for some reason. Let's try outside of the nnloss function
# optimmodel <- results <- modgof <- list()
# for (k in 1:(length(unique(df_lm_agg$CDEC_ID)))){
#   h <- unique(df_lm_agg$CDEC_ID)[k]
#   testset <- df_lm_agg[df_lm_agg$CDEC_ID==h,]
#   trainset <- df_lm_agg[df_lm_agg$CDEC_ID!=h,]
#   
#   # for symmetric losses: seperate into predictor variables and response variable
#   testsetpvs <- as.matrix(testset[,c(15,18:(ncol(testset)-1))])
#   trainsetpvs <- as.matrix(trainset[,c(15,18:(ncol(trainset)-1))])
#   testsetrv <- as.matrix(testset$FLOW)
#   trainsetrv <- as.matrix(trainset$FLOW)
#   
#   # for asymmetric losses: designate each observation as a flood:1 or a drought:0 for asymmetric losses
#   floodlvl_mean <- aggregate(PPT~CDEC_ID, data=trainset, FUN=mean)
#   colnames(floodlvl_mean)[2] <- "FLVL_MEAN"
#   trainset <- merge(trainset, floodlvl_mean, by="CDEC_ID")
#   trainset$FLOOD <- ifelse(trainset$PPT>trainset$FLVL_MEAN, 1, 0) 
#   trainsetpvs2 <- as.matrix(trainset[,c(15, 18:41, 44)]) 
#   trainsetrv2 <- as.matrix(trainset$FLOW)
#   
#   # normalize the training set on standard deviation, then normalize testset by using mean and SD of training set so no leaks happen
#   scale_par <- preProcess(trainsetpvs, method=c("scale"))
#   trainsetpvs_scaled <- data.frame(predict(scale_par, trainsetpvs))
#   testsetpvs_scaled <- predict(scale_par, testsetpvs) # this should remain a matrix
#   # add in the flood column, since the data wasn't shuffled just columnbind
#   trainsetpvs_scaled2 <- trainsetpvs_scaled
#   trainsetpvs_scaled2$FLOOD <- trainset$FLOOD
#   trainsetpvs_scaled2 <- as.matrix(trainsetpvs_scaled2) # back to matrix form 
#   trainsetpvs_scaled <- as.matrix(trainsetpvs_scaled)
#   
#   # the model network includes two layers of fully-connected relu activated neurons, and an output layer with no transformation. units are the number of hidden nodes
#   nnmodel <- keras_model_sequential() %>% # use: "relu", "sigmoid", "softmax"
#     layer_dense(units=64, activation="relu", input_shape=dim(trainsetpvs)[[2]]) %>%
#     layer_dense(units=64, activation="relu") %>%
#     layer_dense(units=1) # number of outputs, here we just want one prediction
#   
#   nnmodel %>% 
#     compile(optimizer="rmsprop", loss=wlse_wrapper_stochastic, metrics=c("mae"))
#   nnmodel %>% 
#     fit(trainsetpvs, trainsetrv, epochs=1000, batch_size=nrow(trainsetpvs), shuffle=FALSE, verbose=1)
#   predictions <- nnmodel %>% predict(testsetpvs)
#   predictions <- predictions[ , 1] 
#   results[[k]] <- cbind(obs=testsetrv[ , 1], pred=predictions, nforstitch=as.numeric(rownames(testset)))
#   modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs)
# }
# 
# names_tbd <- rownames(modgof[[1]])
# modgof <- data.frame(matrix(unlist(modgof), nrow=length(modgof[[1]]), byrow=FALSE))
# rownames(modgof) <- names_tbd
# colnames(modgof) <- unique(df_lm_agg$CDEC_ID)
# nn_agg_logo_wlse_results <- list(results=results, gof=modgof)
# saveRDS(nn_agg_logo_wlse_results, file="ch3 loss functions/outputdata/rds/nn_agg_logo_wlse_results.RDS")
# 
# remove(names_tbd)
# remove(modgof)
# remove(results)
```

```{r nn_linexe}
# # function environments not savind trainsetpvs2 for some reason. Let's try outside of the nnloss function
# optimmodel <- results <- modgof <- list()
# for (k in 1:(length(unique(df_lm_agg$CDEC_ID)))){
#   h <- unique(df_lm_agg$CDEC_ID)[k]
#   testset <- df_lm_agg[df_lm_agg$CDEC_ID==h,]
#   trainset <- df_lm_agg[df_lm_agg$CDEC_ID!=h,]
# 
#   # for symmetric losses: seperate into predictor variables and response variable
#   testsetpvs <- as.matrix(testset[,c(15,18:(ncol(testset)-1))])
#   trainsetpvs <- as.matrix(trainset[,c(15,18:(ncol(trainset)-1))])
#   testsetrv <- as.matrix(testset$FLOW)
#   trainsetrv <- as.matrix(trainset$FLOW)
# 
#   # for asymmetric losses: designate each observation as a flood:1 or a drought:0 for asymmetric losses
#   floodlvl_mean <- aggregate(PPT~CDEC_ID, data=trainset, FUN=mean) 
#   # floodlvl_mean <- aggregate(PPT~CDEC_ID, data=trainset, FUN=median) # let's try median
#   colnames(floodlvl_mean)[2] <- "FLVL_MEAN"
#   trainset <- merge(trainset, floodlvl_mean, by="CDEC_ID")
#   trainset$FLOOD <- ifelse(trainset$PPT>trainset$FLVL_MEAN, 1, 0)
#   trainsetpvs2 <- as.matrix(trainset[,c(15, 18:41, 44)])
#   trainsetrv2 <- as.matrix(trainset$FLOW)
# 
#   # normalize the training set on standard deviation, then normalize testset by using mean and SD of training set so no leaks happen
#   scale_par <- preProcess(trainsetpvs, method=c("scale"))
#   trainsetpvs_scaled <- data.frame(predict(scale_par, trainsetpvs))
#   testsetpvs_scaled <- predict(scale_par, testsetpvs) # this should remain a matrix
#   # add in the flood column, since the data wasn't shuffled just columnbind
#   trainsetpvs_scaled2 <- trainsetpvs_scaled
#   trainsetpvs_scaled2$FLOOD <- trainset$FLOOD
#   trainsetpvs_scaled2 <- as.matrix(trainsetpvs_scaled2) # back to matrix form
#   trainsetpvs_scaled <- as.matrix(trainsetpvs_scaled)
# 
#   # the model network includes two layers of fully-connected relu activated neurons, and an output layer with no transformation. units are the number of hidden nodes
#   nnmodel <- keras_model_sequential() %>% # use: "relu", "sigmoid", "softmax"
#     layer_dense(units=64, activation="relu", input_shape=dim(trainsetpvs)[[2]]) %>%
#     layer_dense(units=64, activation="relu") %>%
#     layer_dense(units=1) # number of outputs, here we just want one prediction
# 
#   nnmodel %>%
#     compile(optimizer="rmsprop", loss=linexe_wrapper_stochastic, metrics=c("mae"))
#   nnmodel %>%
#     fit(trainsetpvs, trainsetrv, epochs=1000, verbose=1, batch_size=nrow(trainsetpvs), shuffle=FALSE)
#   predictions <- nnmodel %>% predict(testsetpvs)
#   predictions <- predictions[ , 1]
#   results[[k]] <- cbind(obs=testsetrv[ , 1], pred=predictions, nforstitch=as.numeric(rownames(testset)))
#   modgof[[k]] <- gof(as.data.frame(results[[k]])$pred, as.data.frame(results[[k]])$obs)
# }
# 
# names_tbd <- rownames(modgof[[1]])
# modgof <- data.frame(matrix(unlist(modgof), nrow=length(modgof[[1]]), byrow=FALSE))
# rownames(modgof) <- names_tbd
# colnames(modgof) <- unique(df_lm_agg$CDEC_ID)
# nn_agg_logo_linexe_results <- list(results=results, gof=modgof)
# saveRDS(nn_agg_logo_linexe_results, file="ch3 loss functions/outputdata/rds/nn_agg_logo_linexe_results.RDS")
# 
# remove(names_tbd)
# remove(modgof)
# remove(results)
```

```{r nn_read_model_runs}
nn_agg_logo_mse_results <- readRDS(file="ch3 loss functions/outputdata/rds/nn_agg_logo_mse_results.RDS")
nn_agg_logo_mae_results <- readRDS(file="ch3 loss functions/outputdata/rds/nn_agg_logo_mae_results.RDS")
nn_agg_logo_msle_results <- readRDS(file="ch3 loss functions/outputdata/rds/nn_agg_logo_msle_results.RDS")
nn_agg_logo_mape_results <- readRDS(file="ch3 loss functions/outputdata/rds/nn_agg_logo_mape_results.RDS")
nn_agg_logo_logcosh_results <- readRDS(file="ch3 loss functions/outputdata/rds/nn_agg_logo_logcosh_results.RDS")
nn_agg_logo_mspe_results <- readRDS(file="ch3 loss functions/outputdata/rds/nn_agg_logo_mspe_results.RDS")
nn_agg_logo_male_results <- readRDS(file="ch3 loss functions/outputdata/rds/nn_agg_logo_male_results.RDS")
nn_agg_logo_msale_results <- readRDS(file="ch3 loss functions/outputdata/rds/nn_agg_logo_msale_results.RDS")
nn_agg_logo_wlse_results <- readRDS("ch3 loss functions/outputdata/rds/nn_agg_logo_wlse_results.RDS")
nn_agg_logo_linexe_results <- readRDS("ch3 loss functions/outputdata/rds/nn_agg_logo_linexe_results.RDS")

# quick check on the results
mean(unlist(nn_agg_logo_mse_results[["gof"]]["bR2", ]))
mean(unlist(nn_agg_logo_mae_results[["gof"]]["bR2", ]))
mean(unlist(nn_agg_logo_msle_results[["gof"]]["bR2", ]))
mean(unlist(nn_agg_logo_mape_results[["gof"]]["bR2", ]), na.rm=TRUE)
mean(unlist(nn_agg_logo_logcosh_results[["gof"]]["bR2", ]))
mean(unlist(nn_agg_logo_mspe_results[["gof"]]["bR2", ]), na.rm=TRUE)
mean(unlist(nn_agg_logo_male_results[["gof"]]["bR2", ]))
mean(unlist(nn_agg_logo_msale_results[["gof"]]["bR2", ]))
mean(unlist(nn_agg_logo_wlse_results[["gof"]]["bR2", ]))
mean(unlist(nn_agg_logo_linexe_results[["gof"]]["bR2", ]))

# investigate why bR2 are returning NA in CSN and other basins?
gof(nn_agg_logo_mape_results$results[[10]][,"pred"],nn_agg_logo_mape_results$results[[10]][,"obs"])
gof(nn_agg_logo_mspe_results$results[[10]][,"pred"],nn_agg_logo_mspe_results$results[[10]][,"obs"])
```

# 5.0 LOGO Post Processing 
```{r data_results_df}
# make a copy of the original dataframes to add the results to later
# notice how the lm, not glm dataset was used for the Tweedie distribution
results_lm_agg <- results_glm_agg <- results_nn_agg <- results_rf_agg <- df_lm_agg
results_lm_inc <- results_glm_inc <- results_nn_inc <- results_rf_inc <- df_lm_inc

# consider putting them all in one dataframe 
results_agg <- df_lm_agg
results_inc <- df_lm_inc
```

## 5.1 Aggregate Basins
```{r post_processing_logo_agg}
pp_agg_results <- function(resultsls, resultsdf, modeltype, losstype){
  results_unlisted <- as.data.frame(do.call("rbind", resultsls$results))
  if(modeltype=="nn"){
    nsubsetting <- results_unlisted$nforstitch
    }
  if(modeltype=="lm"){
    nsubsetting <- as.numeric(rownames(results_unlisted))
    }else{paste0("not valid model type!")}
  results_unlisted <- results_unlisted[order(nsubsetting), ]
  resultsdf <- cbind(resultsdf, FIT=results_unlisted$pred)
  resultsdf$RES <- resultsdf$FIT-resultsdf$FLOW # this is pred - obs
  colnames(resultsdf)[ncol(resultsdf)-1] <- paste0(toupper(modeltype), "_", toupper(losstype), "FIT")
  colnames(resultsdf)[ncol(resultsdf)] <- paste0(toupper(modeltype), "_", toupper(losstype), "RES")
  resultsdf
}

# just going to look at NN now
results_agg <- pp_agg_results(lm_agg_logo_ls_results, results_agg, "lm", "mse")
results_agg <- pp_agg_results(lm_agg_logo_lad_results, results_agg, "lm", "mae")
results_agg <- pp_agg_results(lm_agg_logo_tls_results, results_agg, "lm", "mtse")
results_agg <- pp_agg_results(lm_agg_logo_wls_results, results_agg, "lm", "wlse")
results_agg <- pp_agg_results(lm_agg_logo_linex_results, results_agg, "lm", "linexe")

results_agg <- pp_agg_results(nn_agg_logo_mse_results, results_agg, "nn", "mse")
results_agg <- pp_agg_results(nn_agg_logo_mae_results, results_agg, "nn", "mae")
results_agg <- pp_agg_results(nn_agg_logo_msle_results, results_agg, "nn", "msle")
results_agg <- pp_agg_results(nn_agg_logo_mape_results, results_agg, "nn", "mape")
results_agg <- pp_agg_results(nn_agg_logo_logcosh_results, results_agg, "nn", "logcosh")
results_agg <- pp_agg_results(nn_agg_logo_mspe_results, results_agg, "nn", "mspe")
results_agg <- pp_agg_results(nn_agg_logo_male_results, results_agg, "nn", "male")
results_agg <- pp_agg_results(nn_agg_logo_msale_results, results_agg, "nn", "msale")
results_agg <- pp_agg_results(nn_agg_logo_wlse_results, results_agg, "nn", "wlse")
results_agg <- pp_agg_results(nn_agg_logo_linexe_results, results_agg, "nn", "linexe")
```

## 5.2 Incremental Basins
```{r post_processing_logo_inc} 
# not doing this anymore!!!!
# add the observed data from basins above back in to the incremental predictions. This makes sense for "inc" dataframes and for LOGO CV and LHO CV results only!

pp_lm_logo_inc_losses <- function(lm_inc_logo_loss_results, losstype){
  # put the logo results in the original dataframe format
  lm_inc_logo_results_unlisted <- as.data.frame(do.call("rbind", lm_inc_logo_loss_results$results))
  results_lm_inc <- cbind(results_lm_inc, LMLOGOFIT=lm_inc_logo_results_unlisted$pred)
  
  # put the results in wide format
  library(reshape2)
  results_lm_inc_wide <- dcast(melt(results_lm_inc[,c("DATE", "CDEC_ID", "LMLOGOFIT")], id.vars=c("DATE", "CDEC_ID")), DATE~CDEC_ID) # notice the LMLOGOFIT, that's the fitted values
  
  # results_lm_inc_wide and cdec_fnf_wide should be in the right order and record length should be the same, check. since they don't match, trim cdec_fnf_wide so they do
  cdec_fnf_wide <- cdec_fnf_wide[cdec_fnf_wide$DATE>=min(results_lm_inc_wide$DATE) & cdec_fnf_wide$DATE<=max(results_lm_inc_wide$DATE), ]
  max(results_lm_inc_wide$DATE) == max(cdec_fnf_wide$DATE)
  min(results_lm_inc_wide$DATE) == min(cdec_fnf_wide$DATE)
  
  # make an empty dataframe
  results_lm_inc_agg_wide <- results_lm_inc_wide
  i <- 1
  for(n in colnames(results_lm_inc_wide)[2:length(colnames(results_lm_inc_wide))]){
    b <- substr(n, 1, 3)
    basinabove1 <- basins@data[basins$CDEC_ID == b, "STATIONS_ABOVE1"]
    basinabove2 <- basins@data[basins$CDEC_ID == b, "STATIONS_ABOVE2"]
    basinabove3 <- basins@data[basins$CDEC_ID == b, "STATIONS_ABOVE3"]
    basinabove4 <- basins@data[basins$CDEC_ID == b, "STATIONS_ABOVE4"]
    if(basinabove1!="none"){
      b_ag <- results_lm_inc_wide[, n] + cdec_fnf_wide[, basinabove1]
      if(basinabove2!="none"){
        b_ag <- b_ag + cdec_fnf_wide[, basinabove2]
        if(basinabove3!="none"){
          b_ag <- b_ag + cdec_fnf_wide[, basinabove3]
          if(basinabove4!="none"){
              b_ag <- b_ag + cdec_fnf_wide[, basinabove4]
            } else{b_ag} 
         } else{b_ag}
      } else{b_ag}
    } else{b_ag <- results_lm_inc_wide[, n]}
    results_lm_inc_agg_wide <- cbind(results_lm_inc_agg_wide, b_ag)
    colnames(results_lm_inc_agg_wide)[dim(results_lm_inc_wide)[2]+i] <- paste0(b,"_INC_AGG")
    i <- i+1
  }
  
  # make this back into long format 
  results_lm_inc_agg_long <- melt(results_lm_inc_agg_wide, id.vars="DATE", measure.vars = colnames(results_lm_inc_agg_wide)[69:ncol(results_lm_inc_agg_wide)], value.name = paste0("LMLOGOFIT_AGG_", losstype), variable.name = "CDEC_ID")
  
  # make sure they go back into long format correctly, the dataframes should be the same length, they aren't but we can merge in by id and date
  nrow(results_lm_inc_agg_long) == nrow(results_lm_agg)
  
  # put in results, merge in so that it's joined correctly
  results_lm_inc_agg_long$CDEC_ID_JOIN <- substr(results_lm_inc_agg_long$CDEC_ID, 1, 3)
  results_lm_agg <- merge(results_lm_agg, results_lm_inc_agg_long, by.x=c("DATE", "CDEC_ID"), by.y=c("DATE", "CDEC_ID_JOIN"))
  results_lm_agg[, paste0("LMLOGORES_AGG_", losstype)] <- results_lm_agg[, paste0("LMLOGOFIT_AGG_", losstype)]-results_lm_agg$FLOW
  results_lm_agg <- within(results_lm_agg, rm(CDEC_ID.y))
}

# results_lm_agg <- pp_lm_logo_inc_losses(lm_inc_logo_ls_results, "LS")
# results_lm_agg <-pp_lm_logo_inc_losses(lm_inc_logo_lad_results, "LAD")
# results_lm_agg <-pp_lm_logo_inc_losses(lm_inc_logo_tls_results, "TLS")
# results_lm_agg <-pp_lm_logo_inc_losses(lm_inc_logo_wls_results, "WLS")
# results_lm_agg <-pp_lm_logo_inc_losses(lm_inc_logo_linex_results, "LINEX")
# 
# head(results_lm_agg)
```

All results are in results_agg, use this for plotting. 

## 5.3 GOF Post Processing 
```{r mof_losses_lm}
gof_lm_ls <- gof(results_agg$LM_MSEFIT, results_agg$FLOW, na.rm=TRUE)
gof_lm_lad <- gof(results_agg$LM_MAEFIT, results_agg$FLOW, na.rm=TRUE)
gof_lm_tls <- gof(results_agg$LM_MTSEFIT, results_agg$FLOW, na.rm=TRUE)
gof_lm_wls <- gof(results_agg$LM_WLSEFIT, results_agg$FLOW, na.rm=TRUE)
gof_lm_linex <- gof(results_agg$LM_LINEXEFIT, results_agg$FLOW, na.rm=TRUE)

gof_lm <- cbind(gof_lm_ls, gof_lm_lad, gof_lm_tls, gof_lm_wls, gof_lm_linex)
colnames(gof_lm) <- c("LS", "LAD", "TLS", "WLS", "LINEX")

# use the column names instead, keep everything uppercase
# library(Hmisc)
# var_labels <- c("ls", "lad", "tls", "wls", "linex")
# names(var_labels) <- colnames(gof_lm_inc)
# label(gof_lm_inc) <- unlist(lapply(names(var_labels), function(x) label(gof_lm_inc[,x]) = var_labels[x]))

# for latex documents, put this in appendix
library(xtable)
xtable(data.frame(gof_lm))

# check results
gof_lm["bR2",]
```

```{r mof_losses_nn}
gof_nn_mse <- gof(results_agg$NN_MSEFIT, results_agg$FLOW, na.rm=TRUE)
gof_nn_mae <- gof(results_agg$NN_MAEFIT, results_agg$FLOW, na.rm=TRUE)
gof_nn_msle <- gof(results_agg$NN_MSLEFIT, results_agg$FLOW, na.rm=TRUE)
gof_nn_mape <- gof(results_agg$NN_MAPEFIT, results_agg$FLOW, na.rm=TRUE) 
gof_nn_logcosh <- gof(results_agg$NN_LOGCOSHFIT, results_agg$FLOW, na.rm=TRUE)
gof_nn_mspe <- gof(results_agg$NN_MSPEFIT, results_agg$FLOW, na.rm=TRUE) 
gof_nn_male <- gof(results_agg$NN_MALEFIT, results_agg$FLOW, na.rm=TRUE)
gof_nn_msale <- gof(results_agg$NN_MSALEFIT, results_agg$FLOW, na.rm=TRUE)
gof_nn_wlse <- gof(results_agg$NN_WLSEFIT, results_agg$FLOW, na.rm=TRUE)
gof_nn_linexe <- gof(results_agg$NN_LINEXEFIT, results_agg$FLOW, na.rm=TRUE)

gof_nn <- data.frame(cbind(gof_nn_mse, gof_nn_mae, gof_nn_msle, gof_nn_mape, gof_nn_logcosh, gof_nn_mspe, gof_nn_male, gof_nn_msale, gof_nn_wlse, gof_nn_linexe))
colnames(gof_nn) <- c("MSE_LOSS", "MAE_LOSS","MSLE_LOSS", "MAPE_LOSS", "LOGCOSH_LOSS", "MSPE_LOSS", "MALE_LOSS", "MSALE_LOSS", "WLSE_LOSS", "LINEXE_LOSS")

# use better labels for plots
library(Hmisc)
var_labels <- c(MSE_LOSS="Mean Squared Error", MAE_LOSS="Mean Absolute Error", MSLE_LOSS="Mean Squared Log Error", MAPE_LOSS="Mean Absolute Percentage Error", LOGCOSH_LOSS= "Log Hyperbolic Cosine Error", MSPE_LOSS="Mean Squared Precentage Error", MALE_LOSS="Mean Absolute Log Error", MSALE_LOSS="Mean Squared Log Absolute Error", WLSE_LOSS="Weighted Least Squares Error", LINEXE_LOSS="Linear Exponential Error")
gof_nn <- Hmisc::upData(gof_nn, labels = var_labels)

# for latex documents, put this in appendix
library(xtable)
xtable(data.frame(gof_nn))

# check results
gof_nn["bR2",]
```

```{r mof_lm_bybasin}
gof_lm_ls <- gof_lm_lad <- gof_lm_tls <- gof_lm_wls <- gof_lm_linex <- list()
for (r in 1:(length(unique(results_agg$CDEC_ID)))){ 
  # plot time series by basin
  h <- unique(results_agg$CDEC_ID)[r]
  resultsdf_sub <- results_agg[results_agg$CDEC_ID==h,]
  gof_lm_ls[[r]] <- gof(resultsdf_sub$LM_MSEFIT, resultsdf_sub$FLOW, na.rm=TRUE)
  gof_lm_lad[[r]] <- gof(resultsdf_sub$LM_MAEFIT, resultsdf_sub$FLOW, na.rm=TRUE)
  gof_lm_tls[[r]] <- gof(resultsdf_sub$LM_MTSEFIT, resultsdf_sub$FLOW, na.rm=TRUE)
  gof_lm_wls[[r]] <- gof(resultsdf_sub$LM_WLSEFIT, resultsdf_sub$FLOW, na.rm=TRUE)
  gof_lm_linex[[r]] <- gof(resultsdf_sub$LM_LINEXEFIT, resultsdf_sub$FLOW, na.rm=TRUE)
}

pp_gof_by_basins <- function(gof_list){
  names_tbd <- rownames(gof_list[[1]])
  gof_by_basins <- data.frame(matrix(unlist(gof_list), nrow=length(gof_list[[1]]), byrow=FALSE))
  rownames(gof_by_basins) <- names_tbd
  colnames(gof_by_basins) <- unique(results_agg$CDEC_ID)
  return(gof_by_basins)
}

gof_lm_ls_by_basins <- pp_gof_by_basins(gof_lm_ls)
gof_lm_lad_by_basins <- pp_gof_by_basins(gof_lm_lad)
gof_lm_tls_by_basins <- pp_gof_by_basins(gof_lm_tls)
gof_lm_wls_by_basins <- pp_gof_by_basins(gof_lm_wls)
gof_lm_linex_by_basins <- pp_gof_by_basins(gof_lm_linex)
```

```{r mof_nn_bybasin}
gof_nn_mse <- gof_nn_mae <- gof_nn_msle <- gof_nn_mape <- gof_nn_logcosh <- gof_nn_mspe <- gof_nn_male <- gof_nn_msale <- gof_nn_wlse <- gof_nn_linexe <- list()
for (r in 1:(length(unique(results_agg$CDEC_ID)))){ 
  # plot time series by basin
  h <- unique(results_agg$CDEC_ID)[r]
  resultsdf_sub <- results_agg[results_agg$CDEC_ID==h,]
  gof_nn_mse[[r]] <- gof(resultsdf_sub$NN_MSEFIT, resultsdf_sub$FLOW, na.rm=TRUE)
  gof_nn_mae[[r]] <- gof(resultsdf_sub$NN_MAEFIT, resultsdf_sub$FLOW, na.rm=TRUE)
  gof_nn_msle[[r]] <- gof(resultsdf_sub$NN_MSLEFIT, resultsdf_sub$FLOW, na.rm=TRUE)
  gof_nn_mape[[r]] <- gof(resultsdf_sub$NN_MAPEFIT, resultsdf_sub$FLOW, na.rm=TRUE)
  gof_nn_logcosh[[r]] <- gof(resultsdf_sub$NN_LOGCOSHFIT, resultsdf_sub$FLOW, na.rm=TRUE)
  gof_nn_mspe[[r]] <- gof(resultsdf_sub$NN_MSPEFIT, resultsdf_sub$FLOW, na.rm=TRUE)
  gof_nn_male[[r]] <- gof(resultsdf_sub$NN_MALEFIT, resultsdf_sub$FLOW, na.rm=TRUE)
  gof_nn_msale[[r]] <- gof(resultsdf_sub$NN_MSALEFIT, resultsdf_sub$FLOW, na.rm=TRUE)
  gof_nn_wlse[[r]] <- gof(resultsdf_sub$NN_WLSEFIT, resultsdf_sub$FLOW, na.rm=TRUE)
  gof_nn_linexe[[r]] <- gof(resultsdf_sub$NN_LINEXEFIT, resultsdf_sub$FLOW, na.rm=TRUE)
}

gof_nn_mse_by_basins <- pp_gof_by_basins(gof_nn_mse)
gof_nn_mae_by_basins <- pp_gof_by_basins(gof_nn_mae)
gof_nn_msle_by_basins <- pp_gof_by_basins(gof_nn_msle)
gof_nn_mape_by_basins <- pp_gof_by_basins(gof_nn_mape)
gof_nn_logcosh_by_basins <- pp_gof_by_basins(gof_nn_logcosh)
gof_nn_mspe_by_basins <- pp_gof_by_basins(gof_nn_mspe)
gof_nn_male_by_basins <- pp_gof_by_basins(gof_nn_male)
gof_nn_msale_by_basins <- pp_gof_by_basins(gof_nn_msale)
gof_nn_wlse_by_basins <- pp_gof_by_basins(gof_nn_wlse)
gof_nn_linexe_by_basins <- pp_gof_by_basins(gof_nn_linexe)
```

# 6.0 Plots
## 6.1 Timeseries Visual Fit
MAYBE ADD IN A LINE THAT REPRESENTS THE FLOOD LEVEL DESIGNATION
```{r timeseries_plots} 
# datatype can be: "agg", "inc", "cagg", "cinc"
# modelform can be: "lm" or "nn"

library(reshape2)
library(ggplot2)
tsresultsplots <- function(resultsdf, losstype, modelform){   
  for (r in 1:(length(unique(resultsdf$CDEC_ID)))){ 
    # plot time series by basin
    h <- unique(resultsdf$CDEC_ID)[r]
    resultsdf_sub <- resultsdf[resultsdf$CDEC_ID==h,]
    
    # convert the units. AREASQKM is in square kilometer, PPT is in mm/month, FLOW is in AF/month 
    watershedArea_sqft <- resultsdf_sub$AREASQM[1]*(1000*100/2.54/12)^2
    resultsdf_sub$precip_ft <- resultsdf_sub$PPT/10/2.54/12
    resultsdf_sub$precip_cuft <- resultsdf_sub$precip_ft * watershedArea_sqft
    resultsdf_sub$precip_cfs <- resultsdf_sub$precip_cuft/30.5/24/60/60
    resultsdf_sub$discharge_cfs <- resultsdf_sub$FLOW*0.01656433739228
    
    # get the columns of interest
    if(losstype=="ls"){
      res_of_interest <- resultsdf_sub$LM_MSERES
      fit_of_interest <- resultsdf_sub$LM_MSEFIT
    } else if(losstype=="lad"){
      res_of_interest <- resultsdf_sub$LM_MAERES
      fit_of_interest <- resultsdf_sub$LM_MAEFIT    
    } else if(losstype=="tls"){
      res_of_interest <- resultsdf_sub$LM_MTSERES
      fit_of_interest <- resultsdf_sub$LM_MTSEFIT
    } else if(losstype=="wls"){
      res_of_interest <- resultsdf_sub$LM_WLSERES
      fit_of_interest <- resultsdf_sub$LM_WLSEFIT 
    } else if(losstype=="linex"){
      res_of_interest <- resultsdf_sub$LM_LINEXERES
      fit_of_interest <- resultsdf_sub$LM_LINEXEFIT   
    } else {paste0("not a valid losstype")}
     
    if(losstype=="mse"){
      res_of_interest <- resultsdf_sub$NN_MSERES
      fit_of_interest <- resultsdf_sub$NN_MSEFIT
    }else if(losstype=="mae"){
      res_of_interest <- resultsdf_sub$NN_MAERES
      fit_of_interest <- resultsdf_sub$NN_MAEFIT    
    }else if(losstype=="msle"){
      res_of_interest <- resultsdf_sub$NN_MSLERES
      fit_of_interest <- resultsdf_sub$NN_MSLEFIT    
    }else if(losstype=="mape"){
      res_of_interest <- resultsdf_sub$NN_MAPERES
      fit_of_interest <- resultsdf_sub$NN_MAPEFIT
    }else if(losstype=="logcosh"){
      res_of_interest <- resultsdf_sub$NN_LOGCOSHRES
      fit_of_interest <- resultsdf_sub$NN_LOGCOSHFIT    
    }else if(losstype=="mspe"){
      res_of_interest <- resultsdf_sub$NN_MSPERES
      fit_of_interest <- resultsdf_sub$NN_MSPEFIT    
    }else if(losstype=="male"){
      res_of_interest <- resultsdf_sub$NN_MALERES
      fit_of_interest <- resultsdf_sub$NN_MALEFIT 
    }else if(losstype=="msale"){
      res_of_interest <- resultsdf_sub$NN_MSALERES
      fit_of_interest <- resultsdf_sub$NN_MSALEFIT 
    }else if(losstype=="wlse"){
      res_of_interest <- resultsdf_sub$NN_WLSERES
      fit_of_interest <- resultsdf_sub$NN_WLSEFIT 
    }else if(losstype=="linexe"){
      res_of_interest <- resultsdf_sub$NN_LINEXERES
      fit_of_interest <- resultsdf_sub$NN_LINEXEFIT   
    } else {paste0("not a valid losstype")}
    
    # now convert the units
    resultsdf_sub$discharge_fit_cfs <- fit_of_interest*0.01656433739228
    
    # remove NAs here?
    resultsdf_sub <- na.omit(resultsdf_sub)
    
    # calculate the range needed to avoid having your hyetograph and hydrograph overlap 
    maxRange <- 1.1*(max(resultsdf_sub$precip_cfs) + max(max(resultsdf_sub$discharge_cfs), max(resultsdf_sub$discharge_fit_cfs, na.rm=TRUE)))
  
    # create a function to backtransform the axis labels for precipitation, for some reason multiplying it by -1 fixed the labels, kinda hacky but whatever
    precip_labels <- function(x) {round((-1*x / watershedArea_sqft) * 12 *30.5*24*60*60, 0)} # labels in inches/month
    
    # melt for ggplot dataframe
    results_sub_melted <- melt(resultsdf_sub[, c("DATE", "discharge_cfs", "discharge_fit_cfs" )], id.var='DATE')
    
    # make the plot
    hydrograph <- ggplot(data = results_sub_melted, 
                         aes(x = DATE, y=value, col=variable)) + 
      xlab("")  + 
      ggtitle(paste0('Basin CDEC ID: ', h)) +
      
      # use geom_tile to create the inverted hyetograph. geom_tile has a bug that displays a warning message for height and width, you can ignore it.
      geom_tile(data=resultsdf_sub, aes(y = -1*(precip_cfs/2-maxRange), # y = the center point of each bar
                height = precip_cfs,
                width = 2),
                fill = cbpblack[6],
                color = cbpblack[6]) +
    
      # plot your discharge data
      geom_line() +
      scale_colour_manual("legend:", values = cbpblack[c(1,3)], labels=c("observed", "predicted")) +
      # scale_linetype_manual("legend:", values = c("solid", "dashed")) +
      theme(legend.position="bottom", legend.title = element_blank()) +
    
      # create a second axis with sec_axis() and format the labels to display the original precipitation units
      scale_y_continuous(name = "Discharge (cfs)", sec.axis = sec_axis(trans = ~1*(.-maxRange), name = "Precipitation (in/m)", labels = precip_labels)) # labels are in inches/s
    
    png(paste0('ch3 loss functions/outputdata/timeseries_', modelform, "_", losstype, '/timeseries_', h, '.png'), width=6.5, height=3.5, units="in", pointsize=8, res=1200)
      print(hydrograph)
    dev.off()
  }
}

# tsresultsplots(results_agg, "ls", "lm")
# tsresultsplots(results_agg, "lad", "lm")
# tsresultsplots(results_agg, "tls", "lm")
# tsresultsplots(results_agg, "wls", "lm")
# tsresultsplots(results_agg, "linex", "lm")
# 
# tsresultsplots(results_agg, "mse", "nn")
# tsresultsplots(results_agg, "mae", "nn")
# tsresultsplots(results_agg, "msle", "nn")
# tsresultsplots(results_agg, "mape", "nn")
# tsresultsplots(results_agg, "logcosh", "nn")
# tsresultsplots(results_agg, "mspe", "nn")
# tsresultsplots(results_agg, "male", "nn")
# tsresultsplots(results_agg, "msale", "nn")
# tsresultsplots(results_agg, "wlse", "nn")
# tsresultsplots(results_agg, "linexe", "nn")
```

```{r tsplots_comp_lm} 
for (r in 1:(length(unique(results_agg$CDEC_ID)))){ 
  # plot time series by basin
  h <- unique(results_agg$CDEC_ID)[r]
  resultsdf_sub <- results_agg[results_agg$CDEC_ID==h,]
  
  # convert the units. AREASQKM is in square kilometer, PPT is in mm/month, FLOW is in AF/month 
  watershedArea_sqft <- resultsdf_sub$AREASQM[1]*(1000*100/2.54/12)^2
  resultsdf_sub$precip_ft <- resultsdf_sub$PPT/10/2.54/12
  resultsdf_sub$precip_cuft <- resultsdf_sub$precip_ft * watershedArea_sqft
  resultsdf_sub$precip_cfs <- resultsdf_sub$precip_cuft/30.5/24/60/60
  resultsdf_sub$discharge_cfs <- resultsdf_sub$FLOW*0.01656433739228
  
  resultsdf_sub$LM_MSEFIT_cfs <- resultsdf_sub$LM_MSEFIT*0.01656433739228
  resultsdf_sub$LM_MAEFIT_cfs <- resultsdf_sub$LM_MAEFIT*0.01656433739228
  resultsdf_sub$LM_MTSEFIT_cfs <- resultsdf_sub$LM_MTSEFIT*0.01656433739228
  resultsdf_sub$LM_WLSEFIT_cfs <- resultsdf_sub$LM_WLSEFIT*0.01656433739228
  resultsdf_sub$LM_LINEXEFIT_cfs <- resultsdf_sub$LM_LINEXEFIT*0.01656433739228

  # remove NAs here?
  resultsdf_sub <- na.omit(resultsdf_sub)
  
  # calculate the range needed to avoid having your hyetograph and hydrograph overlap 
  maxFlow <- max(max(resultsdf_sub$discharge_cfs), 
                 max(resultsdf_sub$LM_MSEFIT_cfs, na.rm=TRUE), 
                 max(resultsdf_sub$LM_MAEFIT_cfs, na.rm=TRUE), 
                 max(resultsdf_sub$LM_MTSEFIT_cfs, na.rm=TRUE), 
                 max(resultsdf_sub$LM_WLSEFIT_cfs, na.rm=TRUE), 
                 max(resultsdf_sub$LM_LINEXEFIT_cfs, na.rm=TRUE))
  maxRange <- 1.1*(max(resultsdf_sub$precip_cfs) + maxFlow)

  # create a function to backtransform the axis labels for precipitation, for some reason multiplying it by -1 fixed the labels, kinda hacky but whatever
  precip_labels <- function(x) {round((-1*x/watershedArea_sqft)*12*30.5*24*60*60, 0)} # labels in inches/month
  
  # melt for ggplot dataframe
  results_sub_melted <- melt(resultsdf_sub[, c("DATE", "discharge_cfs", "LM_MSEFIT_cfs", "LM_MAEFIT_cfs", "LM_MTSEFIT_cfs", "LM_WLSEFIT_cfs", "LM_LINEXEFIT_cfs")], id.var='DATE')
  
  # make the plot
  hydrograph <- ggplot(data = results_sub_melted, 
                       aes(x = DATE, y=value, col=variable)) + 
    xlab("")  + 
    ggtitle(paste0('Basin CDEC ID: ', h)) +
    
    # use geom_tile to create the inverted hyetograph. geom_tile has a bug that displays a warning message for height and width, you can ignore it.
    geom_tile(data=resultsdf_sub, aes(y = -1*(precip_cfs/2-maxRange), # y = the center point of each bar
              height = precip_cfs,
              width = 2),
              fill = cbpblack[8],
              color = cbpblack[8]) +
  
    # plot your discharge data
    geom_line() +
    scale_colour_manual("legend:", values = c(cbpblack[1:6]), labels=c("observed", "ls", "lad", "tls", "wls", "linex")) +
    theme(legend.position="bottom", legend.title = element_blank()) +
  
    # create a second axis with sec_axis() and format the labels to display the original precipitation units
    scale_y_continuous(name = "Discharge (cfs)", sec.axis = sec_axis(trans = ~1*(.-maxRange), name = "Precipitation (in/m)", labels = precip_labels)) # labels are in inches/s
  
  png(paste0('ch3 loss functions/outputdata/timeseries_lm_all/timeseries_lm_', h, '.png'), width=6.5, height=3.5, units="in", pointsize=8, res=1200)
    print(hydrograph)
  dev.off()
}
```

```{r tsplots_comp2_lm}
# removed TLS cause it was messing it up
for (r in 1:(length(unique(results_agg$CDEC_ID)))){ 
  # plot time series by basin
  h <- unique(results_lm_agg$CDEC_ID)[r]
  resultsdf_sub <- results_agg[results_agg$CDEC_ID==h,]
  
  # convert the units. AREASQKM is in square kilometer, PPT is in mm/month, FLOW is in AF/month 
  watershedArea_sqft <- resultsdf_sub$AREASQM[1]*(1000*100/2.54/12)^2
  resultsdf_sub$precip_ft <- resultsdf_sub$PPT/10/2.54/12
  resultsdf_sub$precip_cuft <- resultsdf_sub$precip_ft * watershedArea_sqft
  resultsdf_sub$precip_cfs <- resultsdf_sub$precip_cuft/30.5/24/60/60
  resultsdf_sub$discharge_cfs <- resultsdf_sub$FLOW*0.01656433739228
  
  resultsdf_sub$LM_MSEFIT_cfs <- resultsdf_sub$LM_MSEFIT*0.01656433739228
  resultsdf_sub$LM_MAEFIT_cfs <- resultsdf_sub$LM_MAEFIT*0.01656433739228
  resultsdf_sub$LM_WLSEFIT_cfs <- resultsdf_sub$LM_WLSEFIT*0.01656433739228
  resultsdf_sub$LM_LINEXEFIT_cfs <- resultsdf_sub$LM_LINEXEFIT*0.01656433739228

  # remove NAs here?
  resultsdf_sub <- na.omit(resultsdf_sub)
  
  # calculate the range needed to avoid having your hyetograph and hydrograph overlap 
  maxFlow <- max(max(resultsdf_sub$discharge_cfs), 
                 max(resultsdf_sub$LM_MSEFIT_cfs, na.rm=TRUE), 
                 max(resultsdf_sub$LM_MAEFIT_cfs, na.rm=TRUE), 
                 max(resultsdf_sub$LM_WLSEFIT_cfs, na.rm=TRUE), 
                 max(resultsdf_sub$LM_LINEXEFIT_cfs, na.rm=TRUE))
  maxRange <- 1.1*(max(resultsdf_sub$precip_cfs) + maxFlow)

  # create a function to backtransform the axis labels for precipitation, for some reason multiplying it by -1 fixed the labels, kinda hacky but whatever
  precip_labels <- function(x) {round((-1*x/watershedArea_sqft)*12*30.5*24*60*60, 0)} # labels in inches/month
  
  # melt for ggplot dataframe
  results_sub_melted <- melt(resultsdf_sub[, c("DATE", "discharge_cfs", "LM_MSEFIT_cfs", "LM_MAEFIT_cfs", "LM_WLSEFIT_cfs", "LM_LINEXEFIT_cfs")], id.var='DATE')
  
  # make the plot
  hydrograph <- ggplot(data = results_sub_melted, 
                       aes(x = DATE, y=value, col=variable)) + 
    xlab("")  + 
    ggtitle(paste0('Basin CDEC ID: ', h)) +
    
    # use geom_tile to create the inverted hyetograph. geom_tile has a bug that displays a warning message for height and width, you can ignore it.
    geom_tile(data=resultsdf_sub, aes(y = -1*(precip_cfs/2-maxRange), # y = the center point of each bar
              height = precip_cfs,
              width = 2),
              fill = cbpblack[8],
              color = cbpblack[8]) +
  
    # plot your discharge data
    geom_line() +
    scale_colour_manual("legend:", values = c(cbpblack[1:5]), labels=c("observed", "ls", "lad", "wls", "linex")) +
    theme(legend.position="bottom", legend.title = element_blank()) +
  
    # create a second axis with sec_axis() and format the labels to display the original precipitation units
    scale_y_continuous(name = "Discharge (cfs)", sec.axis = sec_axis(trans = ~1*(.-maxRange), name = "Precipitation (in/m)", labels = precip_labels)) # labels are in inches/s
  
  png(paste0('ch3 loss functions/outputdata/timeseries_lm_some/timeseries_lm_', h, '.png'), width=6.5, height=3.5, units="in", pointsize=8, res=1200)
    print(hydrograph)
  dev.off()
}
```

```{r tsplots_comp_nn}
for (r in 1:(length(unique(results_agg$CDEC_ID)))){ 
  # plot time series by basin
  h <- unique(results_agg$CDEC_ID)[r]
  resultsdf_sub <- results_agg[results_agg$CDEC_ID==h,]
  
  # convert the units. AREASQKM is in square kilometer, PPT is in mm/month, FLOW is in AF/month 
  watershedArea_sqft <- resultsdf_sub$AREASQM[1]*(1000*100/2.54/12)^2
  resultsdf_sub$precip_ft <- resultsdf_sub$PPT/10/2.54/12
  resultsdf_sub$precip_cuft <- resultsdf_sub$precip_ft * watershedArea_sqft
  resultsdf_sub$precip_cfs <- resultsdf_sub$precip_cuft/30.5/24/60/60
  resultsdf_sub$discharge_cfs <- resultsdf_sub$FLOW*0.01656433739228
  
  resultsdf_sub$NN_MSEFIT_cfs <- resultsdf_sub$NN_MSEFIT*0.01656433739228
  resultsdf_sub$NN_MAEFIT_cfs <- resultsdf_sub$NN_MAEFIT*0.01656433739228
  resultsdf_sub$NN_MSLEFIT_cfs <- resultsdf_sub$NN_MSLEFIT*0.01656433739228
  resultsdf_sub$NN_MAPEFIT_cfs <- resultsdf_sub$NN_MAPEFIT*0.01656433739228
  resultsdf_sub$NN_LOGCOSHFIT_cfs <- resultsdf_sub$NN_LOGCOSHFIT*0.01656433739228
  resultsdf_sub$NN_MSPEFIT_cfs <- resultsdf_sub$NN_MSPEFIT*0.01656433739228
  resultsdf_sub$NN_MALEFIT_cfs <- resultsdf_sub$NN_MALEFIT*0.01656433739228
  resultsdf_sub$NN_MSALEFIT_cfs <- resultsdf_sub$NN_MSALEFIT*0.01656433739228
  resultsdf_sub$NN_WLSEFIT_cfs <- resultsdf_sub$NN_WLSEFIT*0.01656433739228
  resultsdf_sub$NN_LINEXEFIT_cfs <- resultsdf_sub$NN_LINEXEFIT*0.01656433739228
  
  # remove NAs here?
  resultsdf_sub <- na.omit(resultsdf_sub)
  
  # calculate the range needed to avoid having your hyetograph and hydrograph overlap, try having them overlap cause the graph is hard to read 
  maxFlow <- max(max(resultsdf_sub$discharge_cfs), 
                 max(resultsdf_sub$NN_MSEFIT_cfs, na.rm=TRUE), 
                 max(resultsdf_sub$NN_MAEFIT_cfs, na.rm=TRUE), 
                 # max(resultsdf_sub$NN_MSLEFIT_cfs, na.rm=TRUE),
                 # max(resultsdf_sub$NN_MAPEFIT_cfs, na.rm=TRUE),
                 max(resultsdf_sub$NN_LOGCOSHFIT_cfs, na.rm=TRUE),
                 max(resultsdf_sub$NN_MSPEFIT_cfs, na.rm=TRUE),
                 # max(resultsdf_sub$NN_MALEFIT_cfs, na.rm=TRUE), 
                 # max(resultsdf_sub$NN_MSALEFIT_cfs, na.rm=TRUE),
                 max(resultsdf_sub$NN_WLSEFIT_cfs, na.rm=TRUE),
                 max(resultsdf_sub$NN_LINEXEFIT_cfs, na.rm=TRUE))
  maxRange <- 1*(max(resultsdf_sub$precip_cfs) + maxFlow)

  # create a function to backtransform the axis labels for precipitation, for some reason multiplying it by -1 fixed the labels, kinda hacky but whatever
  precip_labels <- function(x) {round((-1*x/watershedArea_sqft)*12*30.5*24*60*60, 0)} # labels in inches/month
  
  # melt for ggplot dataframe
  results_sub_melted <- melt(resultsdf_sub[, c("DATE", "discharge_cfs", "NN_MSEFIT_cfs", "NN_LOGCOSHFIT_cfs",  "NN_MAEFIT_cfs", "NN_MSPEFIT_cfs", "NN_WLSEFIT_cfs", "NN_LINEXEFIT_cfs")], id.var='DATE')
  
  # make the plot
  hydrograph <- ggplot(data = results_sub_melted, 
                       aes(x = DATE, y=value, col=variable)) + 
    xlab("")  + 
    ggtitle(paste0('Basin CDEC ID: ', h)) +
    
    # use geom_tile to create the inverted hyetograph. geom_tile has a bug that displays a warning message for height and width, you can ignore it.
    geom_tile(data=resultsdf_sub, aes(y = -1*(precip_cfs/2-maxRange), # y = the center point of each bar
              height = precip_cfs,
              width = 2),
              fill = cbpblack[8],
              color = cbpblack[8]) +
  
    # plot your discharge data
    geom_line(aes(linetype=variable)) +
    scale_linetype_manual(values=c("solid", "dashed", "dotted", "dotdash", "longdash", "twodash", "solid"), labels=c("Observed", "MSE", "LOGCOSH", "MAE", "MSPE", "WLSE", "LINEXE"), name="Losses")+
    scale_colour_manual(name="Losses", values = c(cbpblack[1], cbpblack[6], cbpblack[8], cbpblack[5], cbpblack[3], cbpblack[7], cbpblack[2]), labels=c("Observed", "MSE", "LOGCOSH", "MAE", "MSPE", "WLSE", "LINEXE")) +
    theme_bw()+
    theme(legend.position="bottom", legend.title = element_blank()) +
    # create a second axis with sec_axis() and format the labels to display the original precipitation units
    scale_y_continuous(name = "Discharge (cfs)", sec.axis = sec_axis(trans = ~1*(.-maxRange), name = "Precipitation (in/m)", labels = precip_labels)) # labels are in inches/s
    
  png(paste0('ch3 loss functions/outputdata/timeseries_nn_all/timeseries_nn_', h, '.png'), width=6.5, height=8, units="in", pointsize=8, res=1200)
    print(hydrograph)
  dev.off()
}
```

## 6.2 GOF Comparisons
```{r mof_comp_plots}
goftablet <- data.frame(t(gof_nn[, c("MSE_LOSS", "LOGCOSH_LOSS", "MAE_LOSS", "MSPE_LOSS", "WLSE_LOSS", "LINEXE_LOSS")]))

png('ch3 loss functions/outputdata/rplot32_gof_bR2.png', width=6.5, height=1.5, units="in", pointsize=8, res=1200)
  ggplot(goftablet)+
    geom_point(aes(x = bR2, y = reorder(rownames(goftablet), bR2), color=rownames(goftablet)))+
    scale_y_discrete(labels=var_labels[match(rownames(goftablet), names(var_labels))])+
    geom_text(aes(x = bR2, y = reorder(rownames(goftablet), bR2), label=round(bR2, digits=2)), nudge_x = 0.05, size=3)+
    scale_colour_manual(aesthetics=c("colour"), values=c(cbpblack[2], cbpblack[8], cbpblack[5], cbpblack[6], cbpblack[3], cbpblack[7])) +
    theme_bw(base_size = 8) +
    annotate("rect", xmin = 0, xmax = 0.5, ymin = 1, ymax = 6, fill= "grey55", alpha = 0.5) +
    annotate("rect", xmin = 0.5, xmax = 0.65, ymin = 1, ymax = 6, fill= "grey70", alpha = 0.5) +
    annotate("rect", xmin = 0.65, xmax = 0.75, ymin = 1, ymax = 6, fill= "grey85", alpha = 0.5) +
    annotate("rect", xmin = 0.75, xmax = 1.0, ymin = 1, ymax = 6, fill= "grey95", alpha = 0.5) +
    geom_text(aes(x= 0.25, y=6, label="Unsatisfactory"), size=3, hjust="center")+
    geom_text(aes(x= 0.575, y=6, label="Satisfactory"), size=3, hjust="center")+
    geom_text(aes(x= 0.7, y=1, label="Good"), size=3, hjust="center")+
    geom_text(aes(x= 0.875, y=1, label="Very Good"), size=3, hjust="center")+
    ylab("") +
    xlab("Bias-Corrected Coefficient of Determination (-)") +
    theme(legend.title = element_blank(), legend.position = "none") +
    guides(colour = guide_legend(ncol=1), shape = guide_legend(ncol=1))
dev.off()

png('ch3 loss functions/outputdata/rplot32_gof_MSE.png', width=6.5, height=1.5, units="in", pointsize=8, res=1200)
  ggplot(goftablet)+
    geom_point(aes(x = MSE, y = reorder(rownames(goftablet), -MSE), color=rownames(goftablet)))+
    scale_y_discrete(labels=var_labels[match(rownames(goftablet), names(var_labels))])+
    scale_colour_manual(aesthetics=c("colour"), values=c(cbpblack[2], cbpblack[8], cbpblack[5], cbpblack[6], cbpblack[3], cbpblack[7])) +
    theme_bw(base_size = 8) +
    ylab("") +
    xlab("Mean Squared Error ((AF/m)^2)") +
    theme(legend.title = element_blank(), legend.position = "none") +
    guides(colour = guide_legend(ncol=1), shape = guide_legend(ncol=1))
dev.off()

png('ch3 loss functions/outputdata/rplot32_gof_RMSE.png', width=6.5, height=1.5, units="in", pointsize=8, res=1200)
  ggplot(goftablet)+
    geom_point(aes(x = RMSE, y = reorder(rownames(goftablet), -RMSE), color=rownames(goftablet)))+
    scale_y_discrete(labels=var_labels[match(rownames(goftablet), names(var_labels))])+
    scale_colour_manual(aesthetics=c("colour"), values=c(cbpblack[2], cbpblack[8], cbpblack[5], cbpblack[6], cbpblack[3], cbpblack[7])) +
    theme_bw(base_size = 8) +
    ylab("") +
    xlab("Root Mean Squared Error (AF/m)") +
    theme(legend.title = element_blank(), legend.position = "none") +
    guides(colour = guide_legend(ncol=1), shape = guide_legend(ncol=1))
dev.off()

png('ch3 loss functions/outputdata/rplot32_gof_NSE.png', width=6.5, height=1.5, units="in", pointsize=8, res=1200)
  ggplot(goftablet)+
    geom_point(aes(x = NSE, y = reorder(rownames(goftablet), NSE), color=rownames(goftablet)))+
    geom_text(aes(x = NSE, y = reorder(rownames(goftablet), NSE), label=round(NSE, digits=2)), nudge_x = 0.05, size=3)+
    scale_y_discrete(labels=var_labels[match(rownames(goftablet), names(var_labels))])+
    scale_colour_manual(aesthetics=c("colour"), values=c(cbpblack[2], cbpblack[8], cbpblack[5], cbpblack[6], cbpblack[3], cbpblack[7])) +
    theme_bw(base_size = 8) +
    annotate("rect", xmin = 0, xmax = 0.5, ymin = 1, ymax = 6, fill= "grey55", alpha = 0.5) +
    annotate("rect", xmin = 0.5, xmax = 0.65, ymin = 1, ymax = 6, fill= "grey70", alpha = 0.5) +
    annotate("rect", xmin = 0.65, xmax = 0.75, ymin = 1, ymax = 6, fill= "grey85", alpha = 0.5) +
    annotate("rect", xmin = 0.75, xmax = 1.0, ymin = 1, ymax = 6, fill= "grey95", alpha = 0.5) +
    geom_text(aes(x= 0.25, y=6, label="Unsatisfactory"), size=3, hjust="center")+
    geom_text(aes(x= 0.575, y=6, label="Satisfactory"), size=3, hjust="center")+
    geom_text(aes(x= 0.7, y=1, label="Good"), size=3, hjust="center")+
    geom_text(aes(x= 0.875, y=1, label="Very Good"), size=3, hjust="center")+
    ylab("") +
    xlab("Nash Sutcliffe Efficiency Factor (-)") +
    theme(legend.title = element_blank(), legend.position = "none") +
    guides(colour = guide_legend(ncol=1), shape = guide_legend(ncol=1))
dev.off()

png('ch3 loss functions/outputdata/rplot32_gof_VE.png', width=6.5, height=1.5, units="in", pointsize=8, res=1200)
  ggplot(goftablet)+
    geom_point(aes(x = VE, y = reorder(rownames(goftablet), VE), color=rownames(goftablet)))+
    scale_y_discrete(labels=var_labels[match(rownames(goftablet), names(var_labels))])+
    scale_colour_manual(aesthetics=c("colour"), values=c(cbpblack[2], cbpblack[8], cbpblack[5], cbpblack[6], cbpblack[3], cbpblack[7])) +
    theme_bw(base_size = 8) +
    ylab("") +
    xlab("Volumetric Efficiency (-)") +
    theme(legend.title = element_blank(), legend.position = "none") +
    guides(colour = guide_legend(ncol=1), shape = guide_legend(ncol=1))
dev.off()

png('ch3 loss functions/outputdata/rplot32_gof_KGE.png', width=6.5, height=1.5, units="in", pointsize=8, res=1200)
  ggplot(goftablet)+
    geom_point(aes(x = KGE, y = reorder(rownames(goftablet), KGE), color=rownames(goftablet)))+
    scale_y_discrete(labels=var_labels[match(rownames(goftablet), names(var_labels))])+
    scale_colour_manual(aesthetics=c("colour"), values=c(cbpblack[2], cbpblack[8], cbpblack[5], cbpblack[6], cbpblack[3], cbpblack[7])) +
    theme_bw(base_size = 8) +
    ylab("") +
    xlab("Kling Gupta Efficiency (-)") +
    theme(legend.title = element_blank(), legend.position = "none") +
    guides(colour = guide_legend(ncol=1), shape = guide_legend(ncol=1))
dev.off()
```

## 6.3 Observed vs. Predicted 
```{r obsvpred_plots} 
library(reshape2)
master_lm <- results_agg[,c("HIERARCHY", "FLOW", "LM_MSEFIT", "LM_MAEFIT", "LM_MTSEFIT", "LM_WLSEFIT", "LM_LINEXEFIT")]
mastercv_nn <- results_agg[,c("HIERARCHY", "FLOW", "NN_MSEFIT", "NN_LOGCOSHFIT", "NN_MAEFIT", "NN_MSPEFIT", "NN_WLSEFIT", "NN_LINEXEFIT")]
mastercv_nn$HIERARCHY <- factor(mastercv_nn$HIERARCHY, levels=c("1", "2", "3", "4", "5"))
mastercv_nn_melted <- melt(mastercv_nn, id.vars=c("HIERARCHY", "FLOW"), measure.vars=c("NN_MSEFIT", "NN_LOGCOSHFIT", "NN_MAEFIT", "NN_MSPEFIT", "NN_WLSEFIT", "NN_LINEXEFIT"), variable.name="LOSS_FUNCTION", value.name="PRED")

pretty_facet_labels <- c("Mean Squared Error (MSE)", "Mean Log Hyperbolic Cosine Error (LOGCOSH)", "Mean Absolute Error (MAE)", "Mean Squared Percentage Error (MSPE)", "Weighted Least Squares Error (WLSE)", "Linear Exponential Error (LINEXE)")
names(pretty_facet_labels) <- c("NN_MSEFIT", "NN_LOGCOSHFIT", "NN_MAEFIT", "NN_MSPEFIT", "NN_WLSEFIT", "NN_LINEXEFIT")

library(ggpmisc)
png('ch3 loss functions/outputdata/rplot33_obsvspred_all_nn.png', width=6.5, height=8, units="in", pointsize=8, res=1200)
  plottoprint <- ggplot(mastercv_nn_melted, aes(x=FLOW, y=PRED)) +
    geom_point(aes(group=HIERARCHY, colour=HIERARCHY, shape=HIERARCHY)) +
    geom_smooth(method="lm", se=FALSE, color="black")+
    stat_poly_eq(formula = y ~ x, 
                aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
                parse = TRUE) +
    geom_abline(slope=1, intercept=0, color="black", linetype=3)+
    facet_wrap(~LOSS_FUNCTION, ncol=2, labeller=labeller(LOSS_FUNCTION=pretty_facet_labels))+
    scale_discrete_manual(aesthetics = "color", values=c(cbpblack[2], cbpblack[3], cbpblack[4], cbpblack[5], cbpblack[6]), name="Hierarchy")+
    scale_discrete_manual(aesthetics= "shape", values=c(1, 16, 2, 0, 15), name="Hierarchy") +
    labs(x ="Observed Unimpaired Flow (AF/m)", y = "Predicted Unimpaired Flow (AF/m)", color = "")+
    theme(legend.text=element_text(size=10), text=element_text(size=10))+
    theme_bw(base_size = 8)
  print(plottoprint)
dev.off()
```

## 6.4 Density Plots
```{r value_density_plots}
master_cv_1 <- data.frame(results_agg$FLOW)
master_cv_1$LOSS_FUNCTION <- "Observed"
master_cv_2 <- data.frame(results_agg[, "NN_MSEFIT"])
master_cv_2$LOSS_FUNCTION <- "NN_MSEFIT"
master_cv_3 <- data.frame(results_agg[ , "NN_LOGCOSHFIT"])
master_cv_3$LOSS_FUNCTION <- "NN_LOGCOSHFIT"
master_cv_4 <- data.frame(results_agg[ , "NN_MAEFIT"])
master_cv_4$LOSS_FUNCTION <- "NN_MAEFIT"
master_cv_5 <- data.frame(results_agg[ , "NN_MSPEFIT"])
master_cv_5$LOSS_FUNCTION <- "NN_MSPEFIT"
master_cv_6 <- data.frame(results_agg[ , "NN_WLSEFIT"])
master_cv_6$LOSS_FUNCTION <- "NN_WLSEFIT"
master_cv_7 <- data.frame(results_agg[ , "NN_LINEXEFIT"])
master_cv_7$LOSS_FUNCTION <- "NN_LINEXEFIT"

colnames(master_cv_1)[1] <- colnames(master_cv_2)[1] <- colnames(master_cv_3)[1] <- colnames(master_cv_4)[1] <- colnames(master_cv_5)[1] <- colnames(master_cv_6)[1] <- colnames(master_cv_7)[1] <- "FLOW"
  
master_cv <- rbind(master_cv_2, master_cv_3, master_cv_4, master_cv_5, master_cv_6, master_cv_7)
  
plottoprint <- ggplot(master_cv) +
  geom_density(aes(x=FLOW, group=LOSS_FUNCTION, colour=LOSS_FUNCTION, linetype=LOSS_FUNCTION)) +
  scale_color_manual(values=c(cbpblack[6], cbpblack[8], cbpblack[5], cbpblack[3], cbpblack[7], cbpblack[2]), breaks = c("NN_MSEFIT", "NN_LOGCOSHFIT", "NN_MAEFIT", "NN_MSPEFIT", "NN_WLSEFIT", "NN_LINEXEFIT"), name="Pred", labels=c("MSE", "LOGCOSH", "MAE", "MSPE", "WLSE", "LINEXE"))+
  scale_linetype_manual(values=c("dashed", "dotted", "dotdash", "longdash", "twodash", "solid"), breaks = c("NN_MSEFIT", "NN_LOGCOSHFIT", "NN_MAEFIT", "NN_MSPEFIT", "NN_WLSEFIT", "NN_LINEXEFIT"), labels=c("MSE", "LOGCOSH", "MAE", "MSPE", "WLSE", "LINEXE"), name="Pred")+
  geom_density(data=master_cv_1, aes(x=FLOW, fill=LOSS_FUNCTION), alpha=0.2) +
  scale_fill_manual(values=cbpblack[1], name="Obs", label="")+
  guides(fill = guide_legend(override.aes = list(alpha = 0.2)))+
  scale_x_continuous(trans="log10")+
  labs(x ="Unimpaired Flow (AF/m)", y = "Density or Frequency of Occurance (%)", color = "")+
  annotation_logticks(sides = "b")+
  theme(legend.text=element_text(size=10), text=element_text(size=10), legend.position = "bottom")+
  theme_bw(base_size = 8)
    
png(paste0('ch3 loss functions/outputdata/rplot34_density.png'), width=3.25, height=2.85, units="in", pointsize=8, res=1200)
  print(plottoprint)
dev.off()
```

```{r error_density_plots}
master_cv_2 <- data.frame(results_agg[, "NN_MSERES"])
master_cv_2$LOSS_FUNCTION <- "NN_MSERES"
master_cv_3 <- data.frame(results_agg[ , "NN_LOGCOSHRES"])
master_cv_3$LOSS_FUNCTION <- "NN_LOGCOSHRES"
master_cv_4 <- data.frame(results_agg[ , "NN_MAERES"])
master_cv_4$LOSS_FUNCTION <- "NN_MAERES"
master_cv_5 <- data.frame(results_agg[ , "NN_MSPERES"])
master_cv_5$LOSS_FUNCTION <- "NN_MSPERES"
master_cv_6 <- data.frame(results_agg[ , "NN_WLSERES"])
master_cv_6$LOSS_FUNCTION <- "NN_WLSERES"
master_cv_7 <- data.frame(results_agg[ , "NN_LINEXERES"])
master_cv_7$LOSS_FUNCTION <- "NN_LINEXERES"

colnames(master_cv_2)[1] <- colnames(master_cv_3)[1] <- colnames(master_cv_4)[1] <- colnames(master_cv_5)[1] <- colnames(master_cv_6)[1] <- colnames(master_cv_7)[1] <- "FLOW"
  
master_cv <- rbind(master_cv_2, master_cv_3, master_cv_4, master_cv_5, master_cv_6, master_cv_7)
master_cv$LOSS_FUNCTION <- factor(master_cv$LOSS_FUNCTION, levels=c("NN_MSERES", "NN_LOGCOSHRES", "NN_MAERES", "NN_MSPERES", "NN_WLSERES", "NN_LINEXERES"))

loss_labs <- c("MSE", "LOGCOSH", "MAE", "MSPE", "WLSE", "LINEXE")
names(loss_labs) <- c("NN_MSERES", "NN_LOGCOSHRES", "NN_MAERES", "NN_MSPERES", "NN_WLSERES", "NN_LINEXERES")

# NOTE!!! cannot log transform because it gets rid of all negative residuals
plottoprint <- ggplot(master_cv) +
  geom_density(aes(x=FLOW, group=LOSS_FUNCTION, colour=LOSS_FUNCTION), show.legend = FALSE) +
  scale_color_manual(values=c(cbpblack[6], cbpblack[8], cbpblack[5], cbpblack[3], cbpblack[7], cbpblack[2]), breaks = c("NN_MSERES", "NN_LOGCOSHRES", "NN_MAERES", "NN_MSPERES", "NN_WLSERES", "NN_LINEXERES"), name="Pred", labels=c("MSE", "LOGCOSH", "MAE", "MSPE", "WLSE", "LINEXE"))+
  # scale_x_continuous(trans="log10")+ # DO NOT DO THIS
  # annotation_logticks(sides = "b")+
  facet_wrap(~LOSS_FUNCTION, nrow=2, labeller=labeller(LOSS_FUNCTION=loss_labs))+
  labs(x ="Model Residuals, Predicted-Observed (AF/m)", y = "Density or Frequency of Occurance (%)", color = "")+
  theme(legend.text=element_text(size=10), text=element_text(size=10), legend.position = "bottom")+
  theme_bw(base_size = 8)
    
png(paste0('ch3 loss functions/outputdata/rplot34_density_res.png'), width=6.5, height=2.5, units="in", pointsize=8, res=1200)
  print(plottoprint)
dev.off()

# QQ plot to check normality in the distribution
plottoprint <- ggplot(master_cv) +
  stat_qq(aes(sample=FLOW, group=LOSS_FUNCTION, colour=LOSS_FUNCTION, shape=LOSS_FUNCTION), size=1)+
  scale_discrete_manual(aesthetics = "color", values=c(cbpblack[6], cbpblack[8], cbpblack[5], cbpblack[3], cbpblack[7], cbpblack[2]), breaks = c("NN_MSERES", "NN_LOGCOSHRES", "NN_MAERES", "NN_MSPERES", "NN_WLSERES", "NN_LINEXERES"), name="Pred", labels=c("MSE", "LOGCOSH", "MAE", "MSPE", "WLSE", "LINEXE"))+
  scale_shape_manual(values=c(4, 2, 5, 8, 16, 15), breaks = c("NN_MSERES", "NN_LOGCOSHRES", "NN_MAERES", "NN_MSPERES", "NN_WLSERES", "NN_LINEXERES"), name="Pred", labels=c("MSE", "LOGCOSH", "MAE", "MSPE", "WLSE", "LINEXE"))+
  labs(x ="Theoretical", y = "Model Residuals, Predicted-Observed (AF/m)")+
  theme(legend.text=element_text(size=10), text=element_text(size=10), legend.position = "bottom")+
  theme_bw(base_size = 8)

png(paste0('ch3 loss functions/outputdata/rplot34_qqplot_modelres.png'), width=3.25, height=2.85, units="in", pointsize=8, res=1200)
  print(plottoprint)
dev.off()

# ggplot(master_cv, aes(sample=FLOW, group=LOSS_FUNCTION, colour=LOSS_FUNCTION)) + 
#   geom_qq(distribution=qnorm) + 
#   geom_qq_line(line.p=c(0.25, 0.75), col = "lightblue") + ylab("Model Residuals") +
#   facet_wrap(~LOSS_FUNCTION, nrow=3) + 
#   ylab("Model Residuals")
```

## 6.5 Map Plots
```{r error_mapplots}
# modelform can be: "lm", "nn"
library(RColorBrewer)
library(lattice)
library(grid)

br2map <- function(gof_results, losstype, modelform){ 
  basinsc <- basins_points
  results <- data.frame(t(gof_results))
  results$CDEC_ID <- rownames(results)
  basinsc <- merge(basinsc, results, by="CDEC_ID", all=TRUE)
  counties <- list(first=TRUE, "sp.polygons", cacounties, fill="gray88", col="white")

  png(paste0('ch3 loss functions/outputdata/rplot35_br2map_', modelform, "_", losstype , '.png'), width=3.25, height=3, units="in", pointsize=8, res=1200)
  par(mar=c(0,0,0,0)+0.1, cex=1)
  mycolors <- colorRampPalette(c(cbpblack[2],cbpblack[4],cbpblack[6]))
  tbdspplot <- spplot(basinsc["bR2"], cex=0.8, sp.layout=counties, col.regions = mycolors(100), colorkey = list(right = list( # see ?levelplot in package trellis, argument colorkey:
                      fun = draw.colorkey, 
                      args = list(
                             key = list(
                                  at = seq(0, 1.0, 1/100), # colour breaks
                                  col = mycolors(100), # colours
                                  labels = list(
                                      at = seq(0, 1.0, 0.2),
                                      labels = seq(0, 1.0, 0.2)
                                      )
                                   )
                              )
                      )
          )
  )
  print(tbdspplot)
  grid.text("bR2(-)", 0.65, 0.88)
  dev.off()
}

# br2map(gof_lm_ls_by_basins, "ls", "lm")
# br2map(gof_lm_lad_by_basins, "lad", "lm")
# br2map(gof_lm_tls_by_basins, "tls", "lm")
# br2map(gof_lm_wls_by_basins, "wls", "lm")
# br2map(gof_lm_linex_by_basins, "linex", "lm")

br2map(gof_nn_mse_by_basins, "mse", "nn")
br2map(gof_nn_mae_by_basins, "mae", "nn")
br2map(gof_nn_msle_by_basins, "msle", "nn")
br2map(gof_nn_mape_by_basins, "mape", "nn")
br2map(gof_nn_logcosh_by_basins, "logcosh", "nn")
br2map(gof_nn_mspe_by_basins, "mspe", "nn")
br2map(gof_nn_male_by_basins, "male", "nn")
br2map(gof_nn_msale_by_basins, "msale", "nn")
br2map(gof_nn_wlse_by_basins, "wlse", "nn")
br2map(gof_nn_linexe_by_basins, "linexe", "nn")
```

## 6.6 Dotcharts
```{r nn_dotchart}
gofdotchart <- function(gof_results_mse, gof_results_logcosh, gof_results_mae, gof_results_mspe, gof_results_wlse, gof_results_linexe, modeltype, fitofinterest){
  basins_points$HIERARCHY <- (basins_points$STATIONS_ABOVE1!="none") + (basins_points$STATIONS_ABOVE2!="none") + (basins_points$STATIONS_ABOVE3!="none") + (basins_points$STATIONS_ABOVE4!="none") + 1
  basins_points$HIERARCHY <- as.factor(basins_points$HIERARCHY)
  basins_points <- basins_points[,-c(2:(ncol(basins_points)-1))]
    
  tgof_results_mse <- data.frame(t(gof_results_mse))
  tgof_results_mse$CDEC_ID <- rownames(tgof_results_mse)
  basinsc <- basins_points@data
  basinsc <- merge(basinsc, tgof_results_mse, by="CDEC_ID", all=TRUE)
  basinsc$LOSS_FUNCTION <- "MSE"
  
  tgof_results_logcosh <- data.frame(t(gof_results_logcosh))
  tgof_results_logcosh$CDEC_ID <- rownames(tgof_results_logcosh)
  basinsc2 <- basins_points@data
  basinsc2 <- merge(basinsc2, tgof_results_logcosh, by="CDEC_ID", all=TRUE)
  basinsc2$LOSS_FUNCTION <- "LOGCOSH"
  
  tgof_results_mae <- data.frame(t(gof_results_mae))
  tgof_results_mae$CDEC_ID <- rownames(tgof_results_mae)
  basinsc3 <- basins_points@data
  basinsc3 <- merge(basinsc3, tgof_results_mae, by="CDEC_ID", all=TRUE)
  basinsc3$LOSS_FUNCTION <- "MAE"
  
  tgof_results_mspe <- data.frame(t(gof_results_mspe))
  tgof_results_mspe$CDEC_ID <- rownames(tgof_results_mspe)
  basinsc4 <- basins_points@data
  basinsc4 <- merge(basinsc4, tgof_results_mspe, by="CDEC_ID", all=TRUE)
  basinsc4$LOSS_FUNCTION <- "MSPE"
  
  tgof_results_wlse <- data.frame(t(gof_results_wlse))
  tgof_results_wlse$CDEC_ID <- rownames(tgof_results_wlse)
  basinsc5 <- basins_points@data
  basinsc5 <- merge(basinsc5, tgof_results_wlse, by="CDEC_ID", all=TRUE)
  basinsc5$LOSS_FUNCTION <- "WLSE"
  
  tgof_results_linexe <- data.frame(t(gof_results_linexe))
  tgof_results_linexe$CDEC_ID <- rownames(tgof_results_linexe)
  basinsc6 <- basins_points@data
  basinsc6 <- merge(basinsc6, tgof_results_linexe, by="CDEC_ID", all=TRUE)
  basinsc6$LOSS_FUNCTION <- "LINEXE"

  if(fitofinterest=="ME"){
    fitofinterestlabel <- "Mean Error (AF)"
  } else if(fitofinterest=="MAE"){
    fitofinterestlabel <- "Mean Absolute Error (AF)"
  } else if(fitofinterest=="MSE"){
    fitofinterestlabel <- "Mean Squared Error (AF^2)"
  } else if(fitofinterest=="RMSE"){
    fitofinterestlabel <- "Root Mean Squared Error (AF)"
  } else if(fitofinterest=="NRMSE.."){
    fitofinterestlabel <- "Normalized Root Mean Squared Error (AF^2)"
  } else if(fitofinterest=="PBIAS.."){
    fitofinterestlabel <- "Percent Bias (-)"
  } else if(fitofinterest=="RSR"){
    fitofinterestlabel <- "RMSE to Standard Deviation of Observations Ratio (-)"
  } else if(fitofinterest=="NSE"){
    fitofinterestlabel <- "Nash-Sutcliffe Efficiency (-)"
  } else if(fitofinterest=="rSD"){
    fitofinterestlabel <- "Ratio of Standard Deviations (-)"
  } else if(fitofinterest=="mNSE"){
    fitofinterestlabel <- "Modified Nash-Sutcliffe Efficiency (-)"
  } else if(fitofinterest=="rNSE"){
    fitofinterestlabel <- "Relative Nash-Sutcliffe Efficiency (-)"
  } else if(fitofinterest=="d"){
    fitofinterestlabel <- "Index of Agreement (-)"
  } else if(fitofinterest=="md"){
    fitofinterestlabel <- "Modified Index of Agreement (-)"
  } else if(fitofinterest=="rd"){
    fitofinterestlabel <- "Relative Index of Agreement (-)"
  } else if(fitofinterest=="cp"){
    fitofinterestlabel <- "Persistence Index (-)"
  } else if(fitofinterest=="r"){
    fitofinterestlabel <- "Pearson Correlation coefficient (-)"
  } else if(fitofinterest=="R2"){
    fitofinterestlabel <- "Coefficient of Determination (-)"
  } else if(fitofinterest=="bR2"){
    fitofinterestlabel <- "Bias-Corrected Coefficient of Determination (-)"
  } else if(fitofinterest=="KGE"){
    fitofinterestlabel <- "Kling-Gupta Efficiency (-)"
  } else if(fitofinterest=="VE"){
    fitofinterestlabel <- "Volumetric Efficiency (AF)"
  } else{
    print("Input a measure of fit provided by the gof function in HydroGOF package!")
  }
  
  basinscr <- melt(basinsc, id.vars=c("CDEC_ID", "LOSS_FUNCTION", "HIERARCHY"), variable.name = "GOF", value.name="VALUE", measure.vars = fitofinterest)
  basinsc2r <- melt(basinsc2, id.vars=c("CDEC_ID", "LOSS_FUNCTION", "HIERARCHY"), variable.name = "GOF", value.name="VALUE", measure.vars = fitofinterest)
  basinsc3r <- melt(basinsc3, id.vars=c("CDEC_ID", "LOSS_FUNCTION", "HIERARCHY"), variable.name = "GOF", value.name="VALUE", measure.vars = fitofinterest)
  basinsc4r <- melt(basinsc4, id.vars=c("CDEC_ID", "LOSS_FUNCTION", "HIERARCHY"), variable.name = "GOF", value.name="VALUE", measure.vars = fitofinterest)
  basinsc5r <- melt(basinsc5, id.vars=c("CDEC_ID", "LOSS_FUNCTION", "HIERARCHY"), variable.name = "GOF", value.name="VALUE", measure.vars = fitofinterest)
  basinsc6r <- melt(basinsc6, id.vars=c("CDEC_ID", "LOSS_FUNCTION", "HIERARCHY"), variable.name = "GOF", value.name="VALUE", measure.vars = fitofinterest)
  
  # order the basins based on LOGO values, decreasing
  orderrownums <- as.numeric(row.names(basinscr[order(basinscr$VALUE, decreasing=TRUE), ]))
  basinscr <- basinscr[orderrownums, ]
  basinsc2r <- basinsc2r[orderrownums, ]
  basinsc3r <- basinsc3r[orderrownums, ]
  basinsc4r <- basinsc4r[orderrownums, ]
  basinsc5r <- basinsc5r[orderrownums, ]
  basinsc6r <- basinsc6r[orderrownums, ]
  
  # bind aacross the different grouping styles
  basinscm <- rbind(basinscr, basinsc2r, basinsc3r, basinsc4r, basinsc5r, basinsc6r)
  basinscm$LOSS_FUNCTION <- factor(basinscm$LOSS_FUNCTION, levels = c("MSE", "LOGCOSH", "MAE", "MSPE", "WLSE", "LINEXE"))
  basinscm$CDEC_ID <- factor(basinscm$CDEC_ID, levels=basinscm$CDEC_ID[1:67])
  
  plottoprint <- ggplot(data=basinscm, aes(x=VALUE, y=CDEC_ID)) +
      geom_point(aes(shape=LOSS_FUNCTION, color=LOSS_FUNCTION), size=4)+
      facet_grid(HIERARCHY ~ ., scales = "free", space = "free") +
      scale_shape_manual(breaks = c("MSE", "LOGCOSH", "MAE", "MSPE", "WLSE", "LINEXE"), values=c(4, 2, 5, 8, 16, 15)) + 
      scale_colour_manual(aesthetics = c("colour"), values=c(cbpblack[6], cbpblack[8], cbpblack[5], cbpblack[3], cbpblack[7], cbpblack[2]), breaks = c("MSE", "LOGCOSH", "MAE", "MSPE", "WLSE", "LINEXE")) +
      labs(x=fitofinterestlabel, y="")+
      theme_bw()+
      theme(legend.position="bottom", legend.title = element_blank())+
      guides(color = guide_legend(nrow = 1), shape= guide_legend(nrow = 1))
  
  png(paste0('ch3 loss functions/outputdata/rplot310_', modeltype, "_", fitofinterest, 'dotchart_comp.png'), width=6.5, height=8, units="in", pointsize=8, res=1200)
    print(plottoprint)
  dev.off()
}

gofdotchart(gof_nn_mse_by_basins, gof_nn_logcosh_by_basins, gof_nn_mae_by_basins, gof_nn_mspe_by_basins, gof_nn_wlse_by_basins, gof_nn_linexe_by_basins, "nn", "d")
gofdotchart(gof_nn_mse_by_basins, gof_nn_logcosh_by_basins, gof_nn_mae_by_basins, gof_nn_mspe_by_basins, gof_nn_wlse_by_basins, gof_nn_linexe_by_basins, "nn", "bR2")
gofdotchart(gof_nn_mse_by_basins, gof_nn_logcosh_by_basins, gof_nn_mae_by_basins, gof_nn_mspe_by_basins, gof_nn_wlse_by_basins, gof_nn_linexe_by_basins, "nn", "NSE")
gofdotchart(gof_nn_mse_by_basins, gof_nn_logcosh_by_basins, gof_nn_mae_by_basins, gof_nn_mspe_by_basins, gof_nn_wlse_by_basins, gof_nn_linexe_by_basins, "nn", "KGE")
gofdotchart(gof_nn_mse_by_basins, gof_nn_logcosh_by_basins, gof_nn_mae_by_basins, gof_nn_mspe_by_basins, gof_nn_wlse_by_basins, gof_nn_linexe_by_basins, "nn", "VE")
```

## 6.7 Boxplots

## 6.8 GIFs
```{r tsplots_gif}
# just change the naming convention here
for (r in 1:(length(unique(results_agg$CDEC_ID)))){ 
  # plot time series by basin
  h <- unique(results_agg$CDEC_ID)[r]
  resultsdf_sub <- results_agg[results_agg$CDEC_ID==h,]
  
  # convert the units. AREASQKM is in square kilometer, PPT is in mm/month, FLOW is in AF/month 
  watershedArea_sqft <- resultsdf_sub$AREASQM[1]*(1000*100/2.54/12)^2
  resultsdf_sub$precip_ft <- resultsdf_sub$PPT/10/2.54/12
  resultsdf_sub$precip_cuft <- resultsdf_sub$precip_ft * watershedArea_sqft
  resultsdf_sub$precip_cfs <- resultsdf_sub$precip_cuft/30.5/24/60/60
  resultsdf_sub$discharge_cfs <- resultsdf_sub$FLOW*0.01656433739228
  
  resultsdf_sub$NN_MSEFIT_cfs <- resultsdf_sub$NN_MSEFIT*0.01656433739228
  resultsdf_sub$NN_MAEFIT_cfs <- resultsdf_sub$NN_MAEFIT*0.01656433739228
  resultsdf_sub$NN_MSLEFIT_cfs <- resultsdf_sub$NN_MSLEFIT*0.01656433739228
  resultsdf_sub$NN_MAPEFIT_cfs <- resultsdf_sub$NN_MAPEFIT*0.01656433739228
  resultsdf_sub$NN_LOGCOSHFIT_cfs <- resultsdf_sub$NN_LOGCOSHFIT*0.01656433739228
  resultsdf_sub$NN_MSPEFIT_cfs <- resultsdf_sub$NN_MSPEFIT*0.01656433739228
  resultsdf_sub$NN_MALEFIT_cfs <- resultsdf_sub$NN_MALEFIT*0.01656433739228
  resultsdf_sub$NN_MSALEFIT_cfs <- resultsdf_sub$NN_MSALEFIT*0.01656433739228
  resultsdf_sub$NN_WLSEFIT_cfs <- resultsdf_sub$NN_WLSEFIT*0.01656433739228
  resultsdf_sub$NN_LINEXEFIT_cfs <- resultsdf_sub$NN_LINEXEFIT*0.01656433739228
  
  # remove NAs here?
  resultsdf_sub <- na.omit(resultsdf_sub)
  
  # calculate the range needed to avoid having your hyetograph and hydrograph overlap, try having them overlap cause the graph is hard to read 
  maxFlow <- max(max(resultsdf_sub$discharge_cfs), 
                 max(resultsdf_sub$NN_MSEFIT_cfs, na.rm=TRUE), 
                 max(resultsdf_sub$NN_MAEFIT_cfs, na.rm=TRUE), 
                 # max(resultsdf_sub$NN_MSLEFIT_cfs, na.rm=TRUE),
                 # max(resultsdf_sub$NN_MAPEFIT_cfs, na.rm=TRUE),
                 max(resultsdf_sub$NN_LOGCOSHFIT_cfs, na.rm=TRUE),
                 max(resultsdf_sub$NN_MSPEFIT_cfs, na.rm=TRUE),
                 # max(resultsdf_sub$NN_MALEFIT_cfs, na.rm=TRUE), 
                 # max(resultsdf_sub$NN_MSALEFIT_cfs, na.rm=TRUE),
                 max(resultsdf_sub$NN_WLSEFIT_cfs, na.rm=TRUE),
                 max(resultsdf_sub$NN_LINEXEFIT_cfs, na.rm=TRUE))
  maxRange <- 1*(max(resultsdf_sub$precip_cfs) + maxFlow)

  # create a function to backtransform the axis labels for precipitation, for some reason multiplying it by -1 fixed the labels, kinda hacky but whatever
  precip_labels <- function(x) {round((-1*x/watershedArea_sqft)*12*30.5*24*60*60, 0)} # labels in inches/month
  
  # melt for ggplot dataframe
  results_sub_melted <- melt(resultsdf_sub[, c("DATE", "discharge_cfs", "NN_MSEFIT_cfs", "NN_LOGCOSHFIT_cfs",  "NN_MAEFIT_cfs", "NN_MSPEFIT_cfs", "NN_WLSEFIT_cfs", "NN_LINEXEFIT_cfs")], id.var='DATE')
  
  # make the plot
  hydrograph <- ggplot(data = results_sub_melted, 
                       aes(x = DATE, y=value, col=variable)) + 
    xlab("")  + 
    ggtitle(paste0('Basin CDEC ID: ', h)) +
    
    # use geom_tile to create the inverted hyetograph. geom_tile has a bug that displays a warning message for height and width, you can ignore it.
    geom_tile(data=resultsdf_sub, aes(y = -1*(precip_cfs/2-maxRange), # y = the center point of each bar
              height = precip_cfs,
              width = 2),
              fill = cbpblack[8],
              color = cbpblack[8]) +
  
    # plot your discharge data
    geom_line(aes(linetype=variable)) +
    scale_linetype_manual(values=c("solid", "dashed", "dotted", "dotdash", "longdash", "twodash", "solid"), labels=c("Observed", "MSE", "LOGCOSH", "MAE", "MSPE", "WLSE", "LINEXE"), name="Losses")+
    scale_colour_manual(name="Losses", values = c(cbpblack[1], cbpblack[6], cbpblack[8], cbpblack[5], cbpblack[3], cbpblack[7], cbpblack[2]), labels=c("Observed", "MSE", "LOGCOSH", "MAE", "MSPE", "WLSE", "LINEXE")) +
    theme_bw()+
    theme(legend.position="bottom", legend.title = element_blank()) +
    # create a second axis with sec_axis() and format the labels to display the original precipitation units
    scale_y_continuous(name = "Discharge (cfs)", sec.axis = sec_axis(trans = ~1*(.-maxRange), name = "Precipitation (in/m)", labels = precip_labels)) # labels are in inches/s
  
  png(paste0('ch3 loss functions/outputdata/ch3_gif_timeseries_nn_all/timeseries_nn_', r, '.png'), width=6.5, height=8, units="in", pointsize=8, res=1200)
    print(hydrograph)
  dev.off()
}
```

```{r br2map_gif}
br2map <- function(gof_results, losstype, modelform, orderingif){ 
  basinsc <- basins_points
  results <- data.frame(t(gof_results))
  results$CDEC_ID <- rownames(results)
  basinsc <- merge(basinsc, results, by="CDEC_ID", all=TRUE)
  counties <- list(first=TRUE, "sp.polygons", cacounties, fill="gray88", col="white")

  png(paste0('ch3 loss functions/outputdata/ch3_gif_br2maps/rplot35_br2map_', modelform, "_", orderingif, '.png'), width=3.25, height=3, units="in", pointsize=8, res=1200)
  par(mar=c(0,0,0,0)+0.1, cex=1)
  mycolors <- colorRampPalette(c(cbpblack[2],cbpblack[4],cbpblack[6]))
  tbdspplot <- spplot(basinsc["bR2"], cex=0.8, sp.layout=counties, col.regions = mycolors(100), colorkey = list(right = list( # see ?levelplot in package trellis, argument colorkey:
                      fun = draw.colorkey, 
                      args = list(
                             key = list(
                                  at = seq(0, 1.0, 1/100), # colour breaks
                                  col = mycolors(100), # colours
                                  labels = list(
                                      at = seq(0, 1.0, 0.2),
                                      labels = seq(0, 1.0, 0.2)
                                      )
                                   )
                              )
                      )
          )
  )
  print(tbdspplot)
  grid.text("bR2(-)", 0.65, 0.88)
  grid.text(toupper(losstype), 0.43, 0.95)
  dev.off()
}

br2map(gof_nn_mse_by_basins, "mse", "nn", 1)
br2map(gof_nn_logcosh_by_basins, "logcosh", "nn", 2)
br2map(gof_nn_mae_by_basins, "mae", "nn", 3)
br2map(gof_nn_mspe_by_basins, "mspe", "nn", 4)
br2map(gof_nn_wlse_by_basins, "wlse", "nn", 5)
br2map(gof_nn_linexe_by_basins, "linexe", "nn", 6)
```



